{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Under Construction This documentation is under construction. Expect regular changes and updates or missing sections. Welcome to the documentation of EVAdb. The E xome V ariant A nalysis Database serves to streamline analysis of exome cases for the users. In this project we aim to provide a concise documentation for users and administrators of the software alike. Repositories All of EVAdb's source code and files necessary to run the application, can be found on github: EVAdb Pipeline EVAdb is in active use in Munich and Bonn. It has been developed by Tim Strom in Munich and has been used to analyze more than ten thousand exome case over the last years. It is based on perl scripts and a MySQL database. It can be installed directly on bare-matel or a VM or build and deployed via docker. Content Currently this documentation features: Software Architecture Overview Installation Instructions Administration Guide","title":"Home"},{"location":"#home","text":"Under Construction This documentation is under construction. Expect regular changes and updates or missing sections. Welcome to the documentation of EVAdb. The E xome V ariant A nalysis Database serves to streamline analysis of exome cases for the users. In this project we aim to provide a concise documentation for users and administrators of the software alike. Repositories All of EVAdb's source code and files necessary to run the application, can be found on github: EVAdb Pipeline EVAdb is in active use in Munich and Bonn. It has been developed by Tim Strom in Munich and has been used to analyze more than ten thousand exome case over the last years. It is based on perl scripts and a MySQL database. It can be installed directly on bare-matel or a VM or build and deployed via docker.","title":"Home"},{"location":"#content","text":"Currently this documentation features: Software Architecture Overview Installation Instructions Administration Guide","title":"Content"},{"location":"architecture/","text":"Software Architecture EVAdb is built as a collection of perl modules on top of a MySQL database. It can be split logically into three big parts: EVAdb The main user-facing application for variant filtration, annotation. This part will be most often used by normal users aiming to gain insights into their datasets. Admin Application The admin application is the backend of EVAdb. It can be used to create samples as well as managing data access permissions and relationships between groups of or individual samples. Solexa Lims System EVAdb also features a LIMS system for use by wet lab groups. Through this interface, additional information for samples can be provided. Most of the information relating to this part of the application is retrieved from the dna extraction and sequencing processes. We provide setup and usage guides for EVAdb and the Admin Application here. EVAdb The main user interface of the application. With the user interface provided by this application users are able to filter variants based on pre-defined strategies such as autosomal dominant (among others). Admin Application The admin application is used to set meta data and permissions for individual or groups of samples. Selected users should have access to this part of the application to manage sample ingress and curate the available data.","title":"Software Architecture"},{"location":"architecture/#software-architecture","text":"EVAdb is built as a collection of perl modules on top of a MySQL database. It can be split logically into three big parts: EVAdb The main user-facing application for variant filtration, annotation. This part will be most often used by normal users aiming to gain insights into their datasets. Admin Application The admin application is the backend of EVAdb. It can be used to create samples as well as managing data access permissions and relationships between groups of or individual samples. Solexa Lims System EVAdb also features a LIMS system for use by wet lab groups. Through this interface, additional information for samples can be provided. Most of the information relating to this part of the application is retrieved from the dna extraction and sequencing processes. We provide setup and usage guides for EVAdb and the Admin Application here.","title":"Software Architecture"},{"location":"architecture/#evadb","text":"The main user interface of the application. With the user interface provided by this application users are able to filter variants based on pre-defined strategies such as autosomal dominant (among others).","title":"EVAdb"},{"location":"architecture/#admin-application","text":"The admin application is used to set meta data and permissions for individual or groups of samples. Selected users should have access to this part of the application to manage sample ingress and curate the available data.","title":"Admin Application"},{"location":"administration/annotation/","text":"Variant Annotation To upload a vcf file, first it must be annotated using a custom perl pipeline. Docker The following documentation is specific to the Docker version of EVAdb. When using the bare-metal installation your mileage may vary, the general steps remain the same however. VEP It is intended to switch from the custom annotation pipeline to VEP . This documentation will be update accordingly. Annotation is performed at the same time as the actual data upload. For this, we use a set of intermittent annotation and insert steps. Each step performs annotation for things like genes and transcripts based on data from the annotation tables present in the database. For ease of use, the annotation container uses the main script externalPipelineImport.pl as entrypoint interface. To start the import process, the script needs access to a vcf file, the sample id of the sample in the database and the settings name ( hg19_plus ). References with/without chr tags Depending on the Reference that you use for variant calling and alignment, the contigs will be either have the chr prefix (e.g. chr1 ), or not (e.g. 1 ). EVAdb uses the UCSC versions of all contigs, so the prefix must be present. Data Paths The paths to your data most likely differ between the container and the outside world. Make sure to adjust the paths for your mountpoint ( the DATA_DIR configuration variable). Data is mounted to /data inside the container. To import a single or multi-sample vcf file, the following command line is sufficient. docker-compose run annotation -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus Inside the container If you want to open a shell inside the annotation container first, the command can be run as: docker-compose run annotation bash # or the corresponding docker exec perl /pipeline/externalPipelineImport.pl -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus The externalPipelineImport.pl draws most of its runtime information off the current.config.xml file. If you are running via docker, all necessary configuration parameters are set by the src/make_annotation.sh script. If you do run on bare-metal make sure to set the paths in this file such that tool directories and data locations are what is required by the tool. Data Locality With the current iteration of EVAdb and the Docker images all data must be local to the EVAdb server. As noticed in the configuration part , all data directories are entered as docker volume and put through to the container. As such, the data paths differ between container and host. Nevertheless, it is not currently possible to upload samples or data from remote hosts to the machine in excess of what is possible through the use of the web interface. We recommend a data partition or disk with enough storage for your NGS experiments to host this data. This brings two advantages, first you spare the database disk from additional stress (it will be under heavy load on sample import) and additionally you can use cheaper mass storage media to host the bulk (e.g. .bam or .fq.gz ) of your data. Scripts importVCF.sh To upload many samples in quick succession, we use the following script. Breakage - Adjust before use This script is provided as an example for a complete import process. As it is written with the specific configuration of our site in mind it will most likely not work without changes on other systems. #! /bin/bash # vim: ts=4 sw=4 expandtab EVADB_DIR = \"/home/evadb\" INPUT_DIR = \"/gluster/gluster01/share/exome\" function usage { echo -e \"importVCF.sh\\n\\nImport all VCFs of a given Flow Cell into the EVAdb running in $EVADB_DIR as\\ndocker version. Files are searched for in $INPUT_DIR .\\n\\nParameters:\\n\\n\\t-f\\t\\tFlow Cell to import.\\n\\t-h\\t\\tPrint help.\" } PW_FILE = \"/home/evadb/.env\" ROOT_PW = $( grep MYSQL_ROOT_PASSWORD $PW_FILE | cut -d \"=\" -f2 ) while getopts \"f:h\" arg ; do case $arg in f ) FLOW_CELL = \" ${ OPTARG } \" ;; h ) usage exit 0 ;; esac done if [ -z \" $FLOW_CELL \" ] ; then echo -e \"Error: Please supply a flow cell id.\" usage exit 1 fi echo -e \"Searching $INPUT_DIR / $FLOW_CELL /\" ESC_INPUT = $( echo \" ${ INPUT_DIR } \" | sed -e 's/[](&|$|\\|{|}).*[\\^]/\\\\&/g' ) cd $EVADB_DIR for f in $( find \" $INPUT_DIR / $FLOW_CELL /\" -name \"DE*vcf.gz\" ) do BASENAME = $( basename $f ) DIRNAME = $( dirname $f ) SAMPLE = ${ BASENAME %%.* } VCF = \" $DIRNAME / $SAMPLE .chr.vcf\" QUERY = \"select * from sample where name LIKE '% $SAMPLE %' or pedigree LIKE '% $SAMPLE %' or foreignid LIKE '% $SAMPLE %';\" SAMPLE_IN_DB = $( docker-compose exec db mysql -u root -p $ROOT_PW -e \" $QUERY \" exomehg19 | grep \" $SAMPLE \" ) if [[ -n \" $SAMPLE_IN_DB \" ]] ; then echo \"Annotating and Importing $SAMPLE ..\" echo -e \"\\tAdding chr prefix...\" zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF echo -e \"\\tImporting $SAMPLE into evadb...\" docker-compose run annotation -vcf \" ${ VCF / $ESC_INPUT / \\/ data } \" -sample \" $SAMPLE \" -se hg19_plus echo -e \"\\tCleanup...\" rm $VCF else echo -e \"Could not find $SAMPLE in database. Have you create the sample using \\\"Import external samples\\\"?\" fi done cd -","title":"Variant Annotation and Upload"},{"location":"administration/annotation/#variant-annotation","text":"To upload a vcf file, first it must be annotated using a custom perl pipeline. Docker The following documentation is specific to the Docker version of EVAdb. When using the bare-metal installation your mileage may vary, the general steps remain the same however. VEP It is intended to switch from the custom annotation pipeline to VEP . This documentation will be update accordingly. Annotation is performed at the same time as the actual data upload. For this, we use a set of intermittent annotation and insert steps. Each step performs annotation for things like genes and transcripts based on data from the annotation tables present in the database. For ease of use, the annotation container uses the main script externalPipelineImport.pl as entrypoint interface. To start the import process, the script needs access to a vcf file, the sample id of the sample in the database and the settings name ( hg19_plus ). References with/without chr tags Depending on the Reference that you use for variant calling and alignment, the contigs will be either have the chr prefix (e.g. chr1 ), or not (e.g. 1 ). EVAdb uses the UCSC versions of all contigs, so the prefix must be present. Data Paths The paths to your data most likely differ between the container and the outside world. Make sure to adjust the paths for your mountpoint ( the DATA_DIR configuration variable). Data is mounted to /data inside the container. To import a single or multi-sample vcf file, the following command line is sufficient. docker-compose run annotation -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus Inside the container If you want to open a shell inside the annotation container first, the command can be run as: docker-compose run annotation bash # or the corresponding docker exec perl /pipeline/externalPipelineImport.pl -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus The externalPipelineImport.pl draws most of its runtime information off the current.config.xml file. If you are running via docker, all necessary configuration parameters are set by the src/make_annotation.sh script. If you do run on bare-metal make sure to set the paths in this file such that tool directories and data locations are what is required by the tool.","title":"Variant Annotation"},{"location":"administration/annotation/#data-locality","text":"With the current iteration of EVAdb and the Docker images all data must be local to the EVAdb server. As noticed in the configuration part , all data directories are entered as docker volume and put through to the container. As such, the data paths differ between container and host. Nevertheless, it is not currently possible to upload samples or data from remote hosts to the machine in excess of what is possible through the use of the web interface. We recommend a data partition or disk with enough storage for your NGS experiments to host this data. This brings two advantages, first you spare the database disk from additional stress (it will be under heavy load on sample import) and additionally you can use cheaper mass storage media to host the bulk (e.g. .bam or .fq.gz ) of your data.","title":"Data Locality"},{"location":"administration/annotation/#scripts","text":"","title":"Scripts"},{"location":"administration/annotation/#importvcfsh","text":"To upload many samples in quick succession, we use the following script. Breakage - Adjust before use This script is provided as an example for a complete import process. As it is written with the specific configuration of our site in mind it will most likely not work without changes on other systems. #! /bin/bash # vim: ts=4 sw=4 expandtab EVADB_DIR = \"/home/evadb\" INPUT_DIR = \"/gluster/gluster01/share/exome\" function usage { echo -e \"importVCF.sh\\n\\nImport all VCFs of a given Flow Cell into the EVAdb running in $EVADB_DIR as\\ndocker version. Files are searched for in $INPUT_DIR .\\n\\nParameters:\\n\\n\\t-f\\t\\tFlow Cell to import.\\n\\t-h\\t\\tPrint help.\" } PW_FILE = \"/home/evadb/.env\" ROOT_PW = $( grep MYSQL_ROOT_PASSWORD $PW_FILE | cut -d \"=\" -f2 ) while getopts \"f:h\" arg ; do case $arg in f ) FLOW_CELL = \" ${ OPTARG } \" ;; h ) usage exit 0 ;; esac done if [ -z \" $FLOW_CELL \" ] ; then echo -e \"Error: Please supply a flow cell id.\" usage exit 1 fi echo -e \"Searching $INPUT_DIR / $FLOW_CELL /\" ESC_INPUT = $( echo \" ${ INPUT_DIR } \" | sed -e 's/[](&|$|\\|{|}).*[\\^]/\\\\&/g' ) cd $EVADB_DIR for f in $( find \" $INPUT_DIR / $FLOW_CELL /\" -name \"DE*vcf.gz\" ) do BASENAME = $( basename $f ) DIRNAME = $( dirname $f ) SAMPLE = ${ BASENAME %%.* } VCF = \" $DIRNAME / $SAMPLE .chr.vcf\" QUERY = \"select * from sample where name LIKE '% $SAMPLE %' or pedigree LIKE '% $SAMPLE %' or foreignid LIKE '% $SAMPLE %';\" SAMPLE_IN_DB = $( docker-compose exec db mysql -u root -p $ROOT_PW -e \" $QUERY \" exomehg19 | grep \" $SAMPLE \" ) if [[ -n \" $SAMPLE_IN_DB \" ]] ; then echo \"Annotating and Importing $SAMPLE ..\" echo -e \"\\tAdding chr prefix...\" zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF echo -e \"\\tImporting $SAMPLE into evadb...\" docker-compose run annotation -vcf \" ${ VCF / $ESC_INPUT / \\/ data } \" -sample \" $SAMPLE \" -se hg19_plus echo -e \"\\tCleanup...\" rm $VCF else echo -e \"Could not find $SAMPLE in database. Have you create the sample using \\\"Import external samples\\\"?\" fi done cd -","title":"importVCF.sh"},{"location":"administration/disease/","text":"Diseases and Disease Groups Diseases and Disease Groups are an important mechanism in EVAdb. Through use of these features, the system is able to assemble control groups for each query. By default, on each query for autosomal variants the set of variants is checked against summary statistics relating to the disease group that the original sample is part of. To count the number of occurences of a variant in the database, the current disease group is excluded to allow for finding of variants that are rare with respect to the general population (we would expect a disease causing mutation to be more prevalent in the disease group). Parents In many cases, not only the case is sequenced but also the parents. Such trio-analysis cases can be handled through the use of diseases as well. If desired, it is possible to have parents and samples in different disease groups to have parents as controls. Alternatively, they can be set to the same disease group so parents are not included in frequency filters for the case. As such, each sample must be annotated with a disease when it is created. Diseases can be created in the admin application, by using the New disease form. Field Example Description Name Mitochondriopathy Name of the disease (used to reference it) Symbol MT Short hand dispayed in some results tables OmimID 590050 (If available) OmimID corresponding to the disease Disease group Mitochondrial disease Disease group Disease groups can not be modified through the application. They are hard-coded within the database. Disease group table The disease groups are preset in the mariadb database. The default data is included in the exomehg19_diseasegroup.dmp dump. The disease groups can be changed by modifying the table exomehg19.diseasegroup . By default, it is set by calling the following mysql statement. INSERT INTO ` diseasegroup ` VALUES ( 1 , 'Neurological disorder' ), ( 2 , 'Developmental disorder' ), ( 3 , 'Eye disease' ), ( 4 , 'Controls' ), ( 5 , 'Mitochondrial disease' ), ( 6 , 'Tumor' ), ( 7 , 'Immunological disorder' ), ( 8 , 'Heart disease' ), ( 9 , 'Lung disease' ), ( 10 , 'Dermatological disease' ); The available disease groups are: Neurological disorder Developmental disorder Eye disease Controls Mitochondrial disease Tumor Immunological disease Heart disease Lung disease Dermatological disease","title":"Diseases and Disease Groups"},{"location":"administration/disease/#diseases-and-disease-groups","text":"Diseases and Disease Groups are an important mechanism in EVAdb. Through use of these features, the system is able to assemble control groups for each query. By default, on each query for autosomal variants the set of variants is checked against summary statistics relating to the disease group that the original sample is part of. To count the number of occurences of a variant in the database, the current disease group is excluded to allow for finding of variants that are rare with respect to the general population (we would expect a disease causing mutation to be more prevalent in the disease group). Parents In many cases, not only the case is sequenced but also the parents. Such trio-analysis cases can be handled through the use of diseases as well. If desired, it is possible to have parents and samples in different disease groups to have parents as controls. Alternatively, they can be set to the same disease group so parents are not included in frequency filters for the case. As such, each sample must be annotated with a disease when it is created. Diseases can be created in the admin application, by using the New disease form. Field Example Description Name Mitochondriopathy Name of the disease (used to reference it) Symbol MT Short hand dispayed in some results tables OmimID 590050 (If available) OmimID corresponding to the disease Disease group Mitochondrial disease Disease group Disease groups can not be modified through the application. They are hard-coded within the database. Disease group table The disease groups are preset in the mariadb database. The default data is included in the exomehg19_diseasegroup.dmp dump. The disease groups can be changed by modifying the table exomehg19.diseasegroup . By default, it is set by calling the following mysql statement. INSERT INTO ` diseasegroup ` VALUES ( 1 , 'Neurological disorder' ), ( 2 , 'Developmental disorder' ), ( 3 , 'Eye disease' ), ( 4 , 'Controls' ), ( 5 , 'Mitochondrial disease' ), ( 6 , 'Tumor' ), ( 7 , 'Immunological disorder' ), ( 8 , 'Heart disease' ), ( 9 , 'Lung disease' ), ( 10 , 'Dermatological disease' ); The available disease groups are: Neurological disorder Developmental disorder Eye disease Controls Mitochondrial disease Tumor Immunological disease Heart disease Lung disease Dermatological disease","title":"Diseases and Disease Groups"},{"location":"administration/projects/","text":"Projects and Cooperations Projects and Cooperations serve as attribution mechanisms to rellate groups of samples and therefore data to individual accounts and apply a basic set of user permissions. Important It is mandatory to have at least one project and cooperation available prior to first sample upload. By default, the system does not have any cooperations or projects setup. They can be setup through use of the New cooperation and New Project forms respectively. Normally, a cooperation refers to a human being that is collaborating with the owner of the EVAdb instance by sending data in for example. Other uses include setting this to be the absolute owner of the data (in real world terms). A project is owned by a cooperation. As such a project is used to identify sets of samples in a logical relation to each other. Access control may be defined for each project as well as a cooperation. This means that the administrator can restrict access to samples even within users having access to the overarching cooperation. Naming Projects It is recommended to name your projects in upper case with words seperated by underscores ( _ ). This way, forms and fields in the user application will remain more readable even for bigger cohorts. New Cooperation Form New Project Form","title":"Projects and Cooperations"},{"location":"administration/projects/#projects-and-cooperations","text":"Projects and Cooperations serve as attribution mechanisms to rellate groups of samples and therefore data to individual accounts and apply a basic set of user permissions. Important It is mandatory to have at least one project and cooperation available prior to first sample upload. By default, the system does not have any cooperations or projects setup. They can be setup through use of the New cooperation and New Project forms respectively. Normally, a cooperation refers to a human being that is collaborating with the owner of the EVAdb instance by sending data in for example. Other uses include setting this to be the absolute owner of the data (in real world terms). A project is owned by a cooperation. As such a project is used to identify sets of samples in a logical relation to each other. Access control may be defined for each project as well as a cooperation. This means that the administrator can restrict access to samples even within users having access to the overarching cooperation. Naming Projects It is recommended to name your projects in upper case with words seperated by underscores ( _ ). This way, forms and fields in the user application will remain more readable even for bigger cohorts.","title":"Projects and Cooperations"},{"location":"administration/projects/#new-cooperation-form","text":"","title":"New Cooperation Form"},{"location":"administration/projects/#new-project-form","text":"","title":"New Project Form"},{"location":"administration/quick-start/","text":"Administration Guide - Quick Start Quick-Start From running instance to first filter query, the following steps need to be taken in-order: Create a cooperation Create a project Create necessary diseases Create a sample sheet Upload the sample sheet Annotate and upload your vcf files Filter Autosomal (dominant|recessive) or de-novo Once you started the application and have confirmed that it is in working order, you can start to administer your system. This includes setting up users and uploading a first dataset to filter for disease causing variants. All of the following steps are described in greater detail in the different parts of this section. For the impatient, to be able to filter your first case, these are the minimal steps you need to do. Evaluation As there are many moving parts within EVAdb, especially around the annotation side of the application it is good practice to first upload a known solved case to test variant filtration and annotation. Access To follow this guide you need SSH access to the host running EVAdb and admin access to both applications (user and admin). Create a Cooperation and Project Prior to uploading samples, we need to setup the support structure. Goto New cooperation and enter your cooperation details in the form. Typically, this will be your name and details. Afterwards create a project and assign your new cooperation to the project. We assume your cooperation is named Mustermann and the project is called EXOME_CASES . Create diseases For the sample upload and filter processes to work, we need to create some diseases. These tables are not pre-populated. Assuming you start with a single cohort of trio-samples it is advisable to set the parents to a different disease group than the index cases. Create at least two diseases, one \"real\" disease that can be attributed to one of the disease groups and one for the control samples that you assign the disease group Controls . A simple, yet unspecific example could be two diseases: Developmental disorder , DEV (group: Developmental disorder ) and Controls , CTRLS (group: Controls ) Setup a sample sheet The sample sheet is the most convenient way to define multiple sample objects at once. While it is possible to create samples manually or via the LIMS system, we recommend using sample sheets as source of truth. Every row in the sample sheet defines exactly one sample and all its relevant attributes. Most of the columns are mandatory. Upload your sample sheet by using the Import external samples form. Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 The three ID columns Sample ID , Foreign ID and Pedigree are used to identify samples. Additionally, since Pedigree is used as family id, when the same Pedigree is set for multiple samples, we will be able to define the family structure through the web user interface. To be able to use de-novo filter and the like it is necessary to specify the family structure by modifying the generated sample entries. Disease Make sure to set Disease column to the values you used in the previous steps. Annotate and Upload your variants Docker The following part is specific to the docker version of EVAdb. When using a bare-metal or other installation please adjust the commands. After defining samples and the family structure for your cohort, the next step is uploading the variants. The minimum prerequisite other than the previous step is that all data is local to the server that hosts the mariadb container. Database Make sure the database is running and able to handle connections using the MYSQL_USER username prior to starting the annotation container. To make your data available inside the container, set DATA_DIR in your .env file to the directory containing all vcf files that you wish to upload. If you wish to annotate and insert a specific .vcf file, use the following procedure. We assume that the vcf file is located at /share/data/exomes/C1234.vcf.gz and DATA_DIR=/share/data . Then, we can use the following command to upload the variants. This annotation procedure does support uploading multi-sample vcf files. chr Tags EVAdb expects all contigs to have the chr Prefix. Make sure your contigs are named chr1-chrY prior to executing this command. A simple command to change contig names would be the following (although there are some caveats when changing the reference like that). Set $f to your .vcf.gz input and $VCF to the desired output location. zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF docker-compose run annotation -vcf /data/exomes/C1234.vcf.gz \\ -sample C1234 \\ -se hg19_plus Depending on the speed of your system the upload of one sample should be done in less than ten minutes. Afterwards you can try to filter your variant dataset using the tools in the EVAdb user application frontend.","title":"Quick Start"},{"location":"administration/quick-start/#administration-guide-quick-start","text":"Quick-Start From running instance to first filter query, the following steps need to be taken in-order: Create a cooperation Create a project Create necessary diseases Create a sample sheet Upload the sample sheet Annotate and upload your vcf files Filter Autosomal (dominant|recessive) or de-novo Once you started the application and have confirmed that it is in working order, you can start to administer your system. This includes setting up users and uploading a first dataset to filter for disease causing variants. All of the following steps are described in greater detail in the different parts of this section. For the impatient, to be able to filter your first case, these are the minimal steps you need to do. Evaluation As there are many moving parts within EVAdb, especially around the annotation side of the application it is good practice to first upload a known solved case to test variant filtration and annotation. Access To follow this guide you need SSH access to the host running EVAdb and admin access to both applications (user and admin).","title":"Administration Guide - Quick Start"},{"location":"administration/quick-start/#create-a-cooperation-and-project","text":"Prior to uploading samples, we need to setup the support structure. Goto New cooperation and enter your cooperation details in the form. Typically, this will be your name and details. Afterwards create a project and assign your new cooperation to the project. We assume your cooperation is named Mustermann and the project is called EXOME_CASES .","title":"Create a Cooperation and Project"},{"location":"administration/quick-start/#create-diseases","text":"For the sample upload and filter processes to work, we need to create some diseases. These tables are not pre-populated. Assuming you start with a single cohort of trio-samples it is advisable to set the parents to a different disease group than the index cases. Create at least two diseases, one \"real\" disease that can be attributed to one of the disease groups and one for the control samples that you assign the disease group Controls . A simple, yet unspecific example could be two diseases: Developmental disorder , DEV (group: Developmental disorder ) and Controls , CTRLS (group: Controls )","title":"Create diseases"},{"location":"administration/quick-start/#setup-a-sample-sheet","text":"The sample sheet is the most convenient way to define multiple sample objects at once. While it is possible to create samples manually or via the LIMS system, we recommend using sample sheets as source of truth. Every row in the sample sheet defines exactly one sample and all its relevant attributes. Most of the columns are mandatory. Upload your sample sheet by using the Import external samples form. Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 The three ID columns Sample ID , Foreign ID and Pedigree are used to identify samples. Additionally, since Pedigree is used as family id, when the same Pedigree is set for multiple samples, we will be able to define the family structure through the web user interface. To be able to use de-novo filter and the like it is necessary to specify the family structure by modifying the generated sample entries. Disease Make sure to set Disease column to the values you used in the previous steps.","title":"Setup a sample sheet"},{"location":"administration/quick-start/#annotate-and-upload-your-variants","text":"Docker The following part is specific to the docker version of EVAdb. When using a bare-metal or other installation please adjust the commands. After defining samples and the family structure for your cohort, the next step is uploading the variants. The minimum prerequisite other than the previous step is that all data is local to the server that hosts the mariadb container. Database Make sure the database is running and able to handle connections using the MYSQL_USER username prior to starting the annotation container. To make your data available inside the container, set DATA_DIR in your .env file to the directory containing all vcf files that you wish to upload. If you wish to annotate and insert a specific .vcf file, use the following procedure. We assume that the vcf file is located at /share/data/exomes/C1234.vcf.gz and DATA_DIR=/share/data . Then, we can use the following command to upload the variants. This annotation procedure does support uploading multi-sample vcf files. chr Tags EVAdb expects all contigs to have the chr Prefix. Make sure your contigs are named chr1-chrY prior to executing this command. A simple command to change contig names would be the following (although there are some caveats when changing the reference like that). Set $f to your .vcf.gz input and $VCF to the desired output location. zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF docker-compose run annotation -vcf /data/exomes/C1234.vcf.gz \\ -sample C1234 \\ -se hg19_plus Depending on the speed of your system the upload of one sample should be done in less than ten minutes. Afterwards you can try to filter your variant dataset using the tools in the EVAdb user application frontend.","title":"Annotate and Upload your variants"},{"location":"administration/sample/","text":"Sample Management Samples are central to every analysis. For every query, a sample needs to be submitted which is used to filter the variants. All SNV's are associated with one or more sample. A family is denoted by a pedigree id. Filling out sample and pedigree information is prerequisite to the other data upload scripts and can be achieved using a pre-formatted sample sheet. Sample Management To add new samples to the system, please follow the following procedure: Create a sample sheet ( Example ) Upload the sample sheet through \"Import External Data\" Add family information for each sample Sample Sheets A sample sheet can be created as a basic comma separated file. The following columns are mandatory. Column Description Sample ID Unique sample identifier Foreign ID Secondary sample identifier (f.e. external IDs) Pedigree Family id denoting members of one family Comment Arbitrary comment Sex Sex of the patient (\"male\" or \"female\") Affected Affectedness (0/1) Organism Sequenced organism Tissue Tissue that was sequenced (peripheral blood etc.) Disease A name of a disease (must exist in the database) Library Type Sequencing library type Read Type Library sequencing protocol type Exome Assay Exome capture kit used for sequencing Example Sample Sheet Table Sample ID Foreign ID Pedigree Comment Sex Affected Organism Tissue Disease Library Type Read Type Exome Assay 76436 76436 B20-0498 TranslateNamse female 1 human peripheral blood Cases exomic paired-end SureSelect60Mbv6 76443 76443 B20-0498 TranslateNamse male 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 76442 76442 B20-0498 TranslateNamse female 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 .csv File Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 Import External Sample Once you created your sample sheet, it should be uploaded by using the Import external samples form within the admin application. Missing Features Some parts of the import external samples form refer to features that are currently unavailable within the docker or other external deployments. Make sure to set File Extensions to no files , otherwise the import will fail. Entering Family Information While the pedigree ID for each sample can be specified in the sample sheet, the precise family structure can not. For this it is necessary to go through the manual process using the UI. To add family information to a sample, you have to use the admin application. In the admin application, use the following procedure to add the pedigree information (i.e. father/mother). Find the sample using Search samples Click on the Id column of the sample you want to modify Enter mother and father in the corresponding rows","title":"Sample Management"},{"location":"administration/sample/#sample-management","text":"Samples are central to every analysis. For every query, a sample needs to be submitted which is used to filter the variants. All SNV's are associated with one or more sample. A family is denoted by a pedigree id. Filling out sample and pedigree information is prerequisite to the other data upload scripts and can be achieved using a pre-formatted sample sheet. Sample Management To add new samples to the system, please follow the following procedure: Create a sample sheet ( Example ) Upload the sample sheet through \"Import External Data\" Add family information for each sample","title":"Sample Management"},{"location":"administration/sample/#sample-sheets","text":"A sample sheet can be created as a basic comma separated file. The following columns are mandatory. Column Description Sample ID Unique sample identifier Foreign ID Secondary sample identifier (f.e. external IDs) Pedigree Family id denoting members of one family Comment Arbitrary comment Sex Sex of the patient (\"male\" or \"female\") Affected Affectedness (0/1) Organism Sequenced organism Tissue Tissue that was sequenced (peripheral blood etc.) Disease A name of a disease (must exist in the database) Library Type Sequencing library type Read Type Library sequencing protocol type Exome Assay Exome capture kit used for sequencing","title":"Sample Sheets"},{"location":"administration/sample/#example-sample-sheet","text":"","title":"Example Sample Sheet"},{"location":"administration/sample/#table","text":"Sample ID Foreign ID Pedigree Comment Sex Affected Organism Tissue Disease Library Type Read Type Exome Assay 76436 76436 B20-0498 TranslateNamse female 1 human peripheral blood Cases exomic paired-end SureSelect60Mbv6 76443 76443 B20-0498 TranslateNamse male 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 76442 76442 B20-0498 TranslateNamse female 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6","title":"Table"},{"location":"administration/sample/#csv-file","text":"Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6","title":".csv File"},{"location":"administration/sample/#import-external-sample","text":"Once you created your sample sheet, it should be uploaded by using the Import external samples form within the admin application. Missing Features Some parts of the import external samples form refer to features that are currently unavailable within the docker or other external deployments. Make sure to set File Extensions to no files , otherwise the import will fail.","title":"Import External Sample"},{"location":"administration/sample/#entering-family-information","text":"While the pedigree ID for each sample can be specified in the sample sheet, the precise family structure can not. For this it is necessary to go through the manual process using the UI. To add family information to a sample, you have to use the admin application. In the admin application, use the following procedure to add the pedigree information (i.e. father/mother). Find the sample using Search samples Click on the Id column of the sample you want to modify Enter mother and father in the corresponding rows","title":"Entering Family Information"},{"location":"administration/user/","text":"User Management For EVAdb there are multiple types of users. Some users, such as the database users for both applications are fixed. Other users can be created dynamically, through the web user interface, to allow people to logon to the software. Database Users The most primitive user type is the database user. In simple terms, this is the user that is used by the perl backend to retrieve data and send data to and from the mariadb service. Under normal operation, these users should not be touched and provided to the applications once at startup. Security For additional security, it is possible to give differernt user permissions to the respective applications. For the user application, a mostly read-only mysql user is enough. The admin application however requires write permissions to most tables. For the docker version of EVAdb, these users are set through the MYSQL_* .env settings. If using the bare-metal installation, supply a secrets file containing the information. dblogin:<USER> dbpasswd:<PASSWORD> Web Users To be able to login to the application, each user must have a user account created. The initial administrator account will be created on first start, if the docker version is used. To re-create this account, set INIT_USER=\"1\" . This account has administration privilige, meaning you are able to create new accounts within the system. It is also able to login to both, the admin and user systems. When using a bare-metal installation this user needs to be created through the use of mysql. # After logging in to your mysql / mariadb instance # Please change the password INSERT INTO exomevcfe . user ( name , password , role , edit , genesearch , yubikey ) VALUES ( 'admin' , '$2a$08$pmAbhhM2wYD/G9oxziYV3.J9MHwOTG2edQP.RXX.YF2HAhWJ0L1Jm' , 'admin' , 1 , 1 , 0 ); Aside from the initial user, all other users can be created through the use of the web interface. Thee form will allow for the following values to be passed. Field Example Description Name brand Username Password Abcd1234 Password Yubikey 0 Can be set to the yubikey id for two-factor authentication. If you have not enabled yubikey authentication on your system this must be set to 0 . IGV port 10151 Port to manage IGV Cooperations coop1::coop2 List of cooperations this account has access to. If empty, access to all is allowed. Projects proj1::proj2 List of projects the account has access to. If empty, access to all is allowed. Role admin Can be admin or empty. Sets the user as an admin if desired. Gene search 0 Allow user to use gene search features. Burdentests 0 Allow user to use burdentest analysis. Edit 1 Allow user access to the admin application. Failed last Comment Legible Information Arbitrary comment User Creation To create a new user for your EVAdb Frontend, please follow these steps. Choose \"New account\" from the top menu (right-most option) Enter Account Information","title":"User Management"},{"location":"administration/user/#user-management","text":"For EVAdb there are multiple types of users. Some users, such as the database users for both applications are fixed. Other users can be created dynamically, through the web user interface, to allow people to logon to the software.","title":"User Management"},{"location":"administration/user/#database-users","text":"The most primitive user type is the database user. In simple terms, this is the user that is used by the perl backend to retrieve data and send data to and from the mariadb service. Under normal operation, these users should not be touched and provided to the applications once at startup. Security For additional security, it is possible to give differernt user permissions to the respective applications. For the user application, a mostly read-only mysql user is enough. The admin application however requires write permissions to most tables. For the docker version of EVAdb, these users are set through the MYSQL_* .env settings. If using the bare-metal installation, supply a secrets file containing the information. dblogin:<USER> dbpasswd:<PASSWORD>","title":"Database Users"},{"location":"administration/user/#web-users","text":"To be able to login to the application, each user must have a user account created. The initial administrator account will be created on first start, if the docker version is used. To re-create this account, set INIT_USER=\"1\" . This account has administration privilige, meaning you are able to create new accounts within the system. It is also able to login to both, the admin and user systems. When using a bare-metal installation this user needs to be created through the use of mysql. # After logging in to your mysql / mariadb instance # Please change the password INSERT INTO exomevcfe . user ( name , password , role , edit , genesearch , yubikey ) VALUES ( 'admin' , '$2a$08$pmAbhhM2wYD/G9oxziYV3.J9MHwOTG2edQP.RXX.YF2HAhWJ0L1Jm' , 'admin' , 1 , 1 , 0 ); Aside from the initial user, all other users can be created through the use of the web interface. Thee form will allow for the following values to be passed. Field Example Description Name brand Username Password Abcd1234 Password Yubikey 0 Can be set to the yubikey id for two-factor authentication. If you have not enabled yubikey authentication on your system this must be set to 0 . IGV port 10151 Port to manage IGV Cooperations coop1::coop2 List of cooperations this account has access to. If empty, access to all is allowed. Projects proj1::proj2 List of projects the account has access to. If empty, access to all is allowed. Role admin Can be admin or empty. Sets the user as an admin if desired. Gene search 0 Allow user to use gene search features. Burdentests 0 Allow user to use burdentest analysis. Edit 1 Allow user access to the admin application. Failed last Comment Legible Information Arbitrary comment","title":"Web Users"},{"location":"administration/user/#user-creation","text":"To create a new user for your EVAdb Frontend, please follow these steps. Choose \"New account\" from the top menu (right-most option) Enter Account Information","title":"User Creation"},{"location":"installation/","text":"Installation Overview Currently EVAdb supports two methods for installation. It can be installed and run through Docker or natively on the machine. Please see the corresponding sections for further installation details for the different pathways. Docker Native","title":"Overview"},{"location":"installation/#installation-overview","text":"Currently EVAdb supports two methods for installation. It can be installed and run through Docker or natively on the machine. Please see the corresponding sections for further installation details for the different pathways. Docker Native","title":"Installation Overview"},{"location":"installation/docker/build/","text":"Docker Container Docker Container The application, as presented, utilizes multiple docker containers for the components. mariadb EVAdb (docker/snv-hg19p) EVAdb admin (docker/snvedit) init container (helperscripts) annotation (annotation) The EVAdb application consists of two user-facing web interfaces hosted through an Apache Webserver as cgi scripts. To run the application, we also setup the mysql database (mariadb), an init container and an annotation container. The primary use-case of the init container is creation of the database, initial user setup and import of external databases. It should be run on first startup and whenever external data needs changing. The annotation container is intended to be used for the import of vcf files from your standard GATK best practices pipeline. The setup of all containers is done through the docker-compose script ( docker-compose.yml ). Below, we will explain the basic setup of each containers. docker-compose run To execute a tool in a running container of our setup, please use either docker-compose exec [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently running, or docker-compose run [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently shut off. For example, to inspect the database in detail, one can use docker-compose exec db mysql -u <USER> -p<PW> to get a mysql shell in the container. EVAdb and EVAdb Admin Containers Both containers are extended from standard apache/httpd Dockerfiles. We support some environment variables to supply the database user and password data. For each container, the application will run as https web service on port 443 which can be forwarded by standard docker syntax. By default, the user facing filter application will take port 443 of the host and the admin application will use port 8443. Firewall Setup When running a production setup where access to your EVAdb instance from the internet is required it is recommended to run a firewall with only port 443 accessible from the outside. In such a setup, you could access the admin backend only from your local network or through SSH port-forwarding (f.e.) SSL Setup Both containers require a docker volume to be mounted at the /ssl location (can be read-only) containing a certificate and private key file for the SSL connection. The files must be named evadb.crt and evadb.key respectively. Init Container The init container will initialize the database. It creates the first user for the web interface which can then create other users as well. It is built from a standard debian image and installs most software for running the perl scripts to setup the database. First Startup On first start, the EVAdb will typically launch against an unitialized database. In order to function properly, at least INIT_DB and INIT_USER have to be set to 1 to create the database setup and add initial user credentials. It features two docker-volumes which need to be populated with data for the container to work properly. Volume Purpose /library Hosting pre-downloaded external databases (gnomAD, dbNSFP etc.). See the Download Section for more details. /database Database dumps and sql scripts for database creation. The container uses all scripts from this folder to initialize the database. The behaviour of the container can be influenced by setting the IMPORT_* and INIT_* environment variables. This is especially useful if only a single third-party dataset should be reimported. Other values than 1 (e.g. 0 ) will turn off the respective part. Database Wipe If the Init container is run with INIT_DB=1 on an initialized database all data is wiped off the installation. Setting Default Description INIT_DB 1 Initialize the database ( wipes existing data ) INIT_USER 1 Setup admin user and password IMPORT_DBNSFP 1 Toggle import of Polyphen2 and SIFT IMPORT_CADD 1 Toggle import of CADD scores IMPORT_GNOMAD 1 Toggle import of gnomAD IMPORT_DGV 1 Toggle import of dgv structural variation IMPORT_CLINVAR 1 Toggle import of clinvar data IMPORT_UCSC 1 Toggle import of ucsc data IMPORT_CDSDB 1 Toggle import of coding sequence database IMPORT_LOF_METRICS 1 Toggle import of gnomad scores by gene Annotation Container The annotation container is built from the ngs-pipeline repository. Its primary purpose is enabling the import of vcf files for samples. For this, it uses the externalPipelineImport.pl tool as its main interface via entrypoint.sh . Data should be provided via the volume /data . The container expects library data (such as human reference genomes) at /library and databases for annotation at /anno_db . How to use this container to import a VCF file will be described in another section. Build Before the application can be started, application containers have to be built. This can be achieved with the following command. docker-compose build Time Building these containers will take some time. Especially the init and annotation containers have to install a lot of perl modules and take some time before they are ready.","title":"Build"},{"location":"installation/docker/build/#docker-container","text":"Docker Container The application, as presented, utilizes multiple docker containers for the components. mariadb EVAdb (docker/snv-hg19p) EVAdb admin (docker/snvedit) init container (helperscripts) annotation (annotation) The EVAdb application consists of two user-facing web interfaces hosted through an Apache Webserver as cgi scripts. To run the application, we also setup the mysql database (mariadb), an init container and an annotation container. The primary use-case of the init container is creation of the database, initial user setup and import of external databases. It should be run on first startup and whenever external data needs changing. The annotation container is intended to be used for the import of vcf files from your standard GATK best practices pipeline. The setup of all containers is done through the docker-compose script ( docker-compose.yml ). Below, we will explain the basic setup of each containers. docker-compose run To execute a tool in a running container of our setup, please use either docker-compose exec [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently running, or docker-compose run [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently shut off. For example, to inspect the database in detail, one can use docker-compose exec db mysql -u <USER> -p<PW> to get a mysql shell in the container.","title":"Docker Container"},{"location":"installation/docker/build/#evadb-and-evadb-admin-containers","text":"Both containers are extended from standard apache/httpd Dockerfiles. We support some environment variables to supply the database user and password data. For each container, the application will run as https web service on port 443 which can be forwarded by standard docker syntax. By default, the user facing filter application will take port 443 of the host and the admin application will use port 8443. Firewall Setup When running a production setup where access to your EVAdb instance from the internet is required it is recommended to run a firewall with only port 443 accessible from the outside. In such a setup, you could access the admin backend only from your local network or through SSH port-forwarding (f.e.) SSL Setup Both containers require a docker volume to be mounted at the /ssl location (can be read-only) containing a certificate and private key file for the SSL connection. The files must be named evadb.crt and evadb.key respectively.","title":"EVAdb and EVAdb Admin Containers"},{"location":"installation/docker/build/#init-container","text":"The init container will initialize the database. It creates the first user for the web interface which can then create other users as well. It is built from a standard debian image and installs most software for running the perl scripts to setup the database. First Startup On first start, the EVAdb will typically launch against an unitialized database. In order to function properly, at least INIT_DB and INIT_USER have to be set to 1 to create the database setup and add initial user credentials. It features two docker-volumes which need to be populated with data for the container to work properly. Volume Purpose /library Hosting pre-downloaded external databases (gnomAD, dbNSFP etc.). See the Download Section for more details. /database Database dumps and sql scripts for database creation. The container uses all scripts from this folder to initialize the database. The behaviour of the container can be influenced by setting the IMPORT_* and INIT_* environment variables. This is especially useful if only a single third-party dataset should be reimported. Other values than 1 (e.g. 0 ) will turn off the respective part. Database Wipe If the Init container is run with INIT_DB=1 on an initialized database all data is wiped off the installation. Setting Default Description INIT_DB 1 Initialize the database ( wipes existing data ) INIT_USER 1 Setup admin user and password IMPORT_DBNSFP 1 Toggle import of Polyphen2 and SIFT IMPORT_CADD 1 Toggle import of CADD scores IMPORT_GNOMAD 1 Toggle import of gnomAD IMPORT_DGV 1 Toggle import of dgv structural variation IMPORT_CLINVAR 1 Toggle import of clinvar data IMPORT_UCSC 1 Toggle import of ucsc data IMPORT_CDSDB 1 Toggle import of coding sequence database IMPORT_LOF_METRICS 1 Toggle import of gnomad scores by gene","title":"Init Container"},{"location":"installation/docker/build/#annotation-container","text":"The annotation container is built from the ngs-pipeline repository. Its primary purpose is enabling the import of vcf files for samples. For this, it uses the externalPipelineImport.pl tool as its main interface via entrypoint.sh . Data should be provided via the volume /data . The container expects library data (such as human reference genomes) at /library and databases for annotation at /anno_db . How to use this container to import a VCF file will be described in another section.","title":"Annotation Container"},{"location":"installation/docker/build/#build","text":"Before the application can be started, application containers have to be built. This can be achieved with the following command. docker-compose build Time Building these containers will take some time. Especially the init and annotation containers have to install a lot of perl modules and take some time before they are ready.","title":"Build"},{"location":"installation/docker/configuration/","text":"Configuration The original software of EVAdb is not very configurable and does not feature any dedicated configuration files. Therefore, the options for configuration are very limited. Nevertheless all of the following parameters should be set in your docker .env file prior to build time. Docker .env Make sure you understand the basics behind docker environment variables and how the .env file fits in. Read more: Environment variables in Compose The following parameters are available to be configured. Please also see the example file at the end of this section. Setting Description Example MYSQL_ROOT_PASSWORD Password of the mysql root user sup3rs3cur3 MYSQL_PASSWORD Password for the mysql user myPass MYSQL_USER Username for the mysql account evadb MYSQL_DATABASE Standard mysql database solexa YUBIKEY_ID Yubikey ID (if present) test YUBIKEY_APIKEY Yubikey api key secr3t DATABASE_DIR Persistent database storage dir /big_storage CURRENT_UID UID and GID to run the database with normal user permissions 1000:1000 CERT_DIR Directory where certificates are stored /secrets INITIAL_USER Initial evadb user name admin INITIAL_USER_PASSWD Password for the initial evadb user abc123 ANNO_DB_DIR Location of annotation databases (gnomAD, dbNSFP etc.) /anno_db LIBRARY Location for library files (reference genomes etc.) /reference DATA_DIR Directory containing data files for upload (vcf etc.) /data Example .env File Setting CURRENT_UID To set the CURRENT_UID parameter for your own user, use the result of the command: echo \" $( id -u ) : $( id -g ) \" The following is an example .env file. MYSQL_ROOT_PASSWORD = root_pw MYSQL_PASSWORD = user_pass MYSQL_USER = evadb MYSQL_DATABASE = solexa YUBIKEY_ID = test YUBIKEY_APIKEY = secr3t DATABASE_DIR = /evadb CURRENT_UID = 1000 :1000 CERT_DIR = /home/evadb/secrets/ INITIAL_USER = admin INITIAL_USER_PASSWD = admin_pw ANNO_DB_DIR = /annotation_db/ LIBRARY = /library/ DATA_DIR = /data/","title":"Configuration"},{"location":"installation/docker/configuration/#configuration","text":"The original software of EVAdb is not very configurable and does not feature any dedicated configuration files. Therefore, the options for configuration are very limited. Nevertheless all of the following parameters should be set in your docker .env file prior to build time. Docker .env Make sure you understand the basics behind docker environment variables and how the .env file fits in. Read more: Environment variables in Compose The following parameters are available to be configured. Please also see the example file at the end of this section. Setting Description Example MYSQL_ROOT_PASSWORD Password of the mysql root user sup3rs3cur3 MYSQL_PASSWORD Password for the mysql user myPass MYSQL_USER Username for the mysql account evadb MYSQL_DATABASE Standard mysql database solexa YUBIKEY_ID Yubikey ID (if present) test YUBIKEY_APIKEY Yubikey api key secr3t DATABASE_DIR Persistent database storage dir /big_storage CURRENT_UID UID and GID to run the database with normal user permissions 1000:1000 CERT_DIR Directory where certificates are stored /secrets INITIAL_USER Initial evadb user name admin INITIAL_USER_PASSWD Password for the initial evadb user abc123 ANNO_DB_DIR Location of annotation databases (gnomAD, dbNSFP etc.) /anno_db LIBRARY Location for library files (reference genomes etc.) /reference DATA_DIR Directory containing data files for upload (vcf etc.) /data","title":"Configuration"},{"location":"installation/docker/configuration/#example-env-file","text":"Setting CURRENT_UID To set the CURRENT_UID parameter for your own user, use the result of the command: echo \" $( id -u ) : $( id -g ) \" The following is an example .env file. MYSQL_ROOT_PASSWORD = root_pw MYSQL_PASSWORD = user_pass MYSQL_USER = evadb MYSQL_DATABASE = solexa YUBIKEY_ID = test YUBIKEY_APIKEY = secr3t DATABASE_DIR = /evadb CURRENT_UID = 1000 :1000 CERT_DIR = /home/evadb/secrets/ INITIAL_USER = admin INITIAL_USER_PASSWD = admin_pw ANNO_DB_DIR = /annotation_db/ LIBRARY = /library/ DATA_DIR = /data/","title":"Example .env File"},{"location":"installation/docker/download/","text":"Download To be able to build and run the software, we first need to download the scripts and binary files. Additionally to have a fully functioning EVAdb many third-party datasets should also be downloaded. Data from gnomAD , dbSNP and others is used in many filtering steps to find rare variants or variants associated with the given phenotype of the patient. After downloading the scripts and Dockerfiles, we will build the container images. Are pre-built Docker containers available for EVAdb? Currently, the Docker containers for EVAdb are not available on a public docker registry. Therefore, the images must be built on a local machine before use. EVAdb All files necessary to deploy EVAdb can be found in the git repository of EVAdb ( here ). The docker branch contains Dockerfiles and docker-compose scripts for building and installing the software. Proxy If youre locked behind a restrictive proxy that you need to access the internet from your build host you have to adapt the Dockerfiles. Currently, it is necessary to set the http_proxy and https_proxy environment variables. # Prefix each Dockerfile with ENV http_proxy http://<USER>:<PW>@<IP>:<PORT>/ ENV https_proxy http://<USER>:<PW>@<IP>:<PORT>/ RUN git config --global https.proxy ${ https_proxy } \\ && git config --global http.proxy ${ http_proxy } \\ && git config --global https.proxyAuthMethod basic \\ && git config --global http.proxyAuthMethod basic To clone the EVAdb docker branch, use git clone -b docker https://github.com/mri-ihg/EVAdb.git Third-Party Data When building the container images and on first startup of the application, it is recommended to have some third party datasets available. It is possible to run the application without this data for development purposes, but in a production setup these datasets should be present in order for all features to work as expected (f.e. gnomAD filtering). hg19 vs GRCh38 All library file URL's have to be adjusted for hg38 If you intend to process hg38 with the current version of EVAdb, make sure to include the correct library files. All URL's in the table below are for hg19 . Dataset Storage Some of the datasets are very large. gnomAD genomes for example exceeds 200GB in size. Make sure to have enough disk space available when downloading these assets. Dataset Description URL dbNSFP Polyphen2 and SIFT scores are taken from dbNSFP ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFPv3.5a.zip CADD Cadd scores https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh37/whole_genome_SNVs.tsv.gz gnomAD Genome aggregation database Exome and Genome builds https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.vcf.bgz OMIM Mendelian inheritance in men Request individual acces at omim.org","title":"Download"},{"location":"installation/docker/download/#download","text":"To be able to build and run the software, we first need to download the scripts and binary files. Additionally to have a fully functioning EVAdb many third-party datasets should also be downloaded. Data from gnomAD , dbSNP and others is used in many filtering steps to find rare variants or variants associated with the given phenotype of the patient. After downloading the scripts and Dockerfiles, we will build the container images. Are pre-built Docker containers available for EVAdb? Currently, the Docker containers for EVAdb are not available on a public docker registry. Therefore, the images must be built on a local machine before use.","title":"Download"},{"location":"installation/docker/download/#evadb","text":"All files necessary to deploy EVAdb can be found in the git repository of EVAdb ( here ). The docker branch contains Dockerfiles and docker-compose scripts for building and installing the software. Proxy If youre locked behind a restrictive proxy that you need to access the internet from your build host you have to adapt the Dockerfiles. Currently, it is necessary to set the http_proxy and https_proxy environment variables. # Prefix each Dockerfile with ENV http_proxy http://<USER>:<PW>@<IP>:<PORT>/ ENV https_proxy http://<USER>:<PW>@<IP>:<PORT>/ RUN git config --global https.proxy ${ https_proxy } \\ && git config --global http.proxy ${ http_proxy } \\ && git config --global https.proxyAuthMethod basic \\ && git config --global http.proxyAuthMethod basic To clone the EVAdb docker branch, use git clone -b docker https://github.com/mri-ihg/EVAdb.git","title":"EVAdb"},{"location":"installation/docker/download/#third-party-data","text":"When building the container images and on first startup of the application, it is recommended to have some third party datasets available. It is possible to run the application without this data for development purposes, but in a production setup these datasets should be present in order for all features to work as expected (f.e. gnomAD filtering). hg19 vs GRCh38 All library file URL's have to be adjusted for hg38 If you intend to process hg38 with the current version of EVAdb, make sure to include the correct library files. All URL's in the table below are for hg19 . Dataset Storage Some of the datasets are very large. gnomAD genomes for example exceeds 200GB in size. Make sure to have enough disk space available when downloading these assets. Dataset Description URL dbNSFP Polyphen2 and SIFT scores are taken from dbNSFP ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFPv3.5a.zip CADD Cadd scores https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh37/whole_genome_SNVs.tsv.gz gnomAD Genome aggregation database Exome and Genome builds https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.vcf.bgz OMIM Mendelian inheritance in men Request individual acces at omim.org","title":"Third-Party Data"},{"location":"installation/docker/prerequisites/","text":"Prerequisites In order to run the docker version of EVAdb in a secure and performant manner, some prerequisites need to be fulfilled. Please make sure that you have a basic understanding of docker and how the web works before setting up this website. In order to follow setup and usage guides, it is important that you have an understanding on docker, SSL certificates (for https) and the performance of the system you are hosting your database at. Physical Infrastructure Hardware Requirements To be able to host EVAdb, the hardware must have: 4TB NVMe/SSD Storage Additional performance improvements are gained by utilizing more RAM and CPU Power. EVAdb is meant to host multiple thousand exome cases. As is the case with such datasets, even storing only variants will have the database growing to be multiple terabytes in size. In order to have a nice user experience for the frontend, it is important that the backend database does not bog down even for large requests (f.e. all autosomal dominant variants for one sample). To be able to scale the amount of data, we recommend a physical server utilizing NVMe (or at least SSD) storage technologies. This will greatly increase the database performance for all queries. Make sure you have enough storage available for the expected amount of data. The initialized application will consume around 400GB without any cases added. Spinning Rust We advise heavily against running the databse on older HDD type storage media. Performance will be abysmal. Docker Docker Docker is a isolation technique prevalent in modern software development since it allows the automatic deployment of complex software stacks. Read more: Docker Get Started Docker Setup To be able to host EVAdb through Docker Images, make sure you have installed and correctly configured: Docker docker-compose If you desire to install the application via Docker, please familiarize yourself with the basic concepts of Docker. To deploy the application, we use docker-compose which allows us to deploy the stack of multiple containers through use of a single command. Please follow the installation instructions for docker on your favorite operating system over at docker.com . Some operating systems might need additional setup after installation of docker, typically adding the active user to the docker group. Make sure you follow these steps as well (postinstallation) . To be able to continue with the installation guide, please also install docker-compose . SSL Certificates SSL Certificates Obtaining a certificate and private key pair is necessary to host EVAdb. Make sure you have obtained a pair and named them evadb.crt and evadb.key to run the application. SSL is used in https to encrypt connections to remote servers. In order to validate the servers identity to the client, the server needs to present a valid certificate. Valid certificates can be obtained from letsencrypt or your local universities IT department. To run EVAdb, you have to supply a certificate for use by the web service. Letsencrypt In order to use the following letsencrypt description, your server needs to be reachable from the Internet and have a known DNS entry. In order to request a valid certificate from letsencrypt, you can use the certbot application. It can be installed on any UNIX-like machine through the package manager of choice. Once installed, use certbot certonly --standalone to get a certificate for your server. For development purposes, it is enough to create a self-signed certificate. On UNIX-like machines the openssl tool can be used to create a self-signed certificate for use with EVAdb. openssl req -x509 -newkey rsa:4096 \\ -keyout <KEY_NAME> \\ -out <CERT_NAME> \\ -days 365 \\ --nodes This will print your certificate and its private key at KEY_NAME and CERT_NAME respectively. To supply the certificate and private key to evadb, they have to be named evadb.crt and evadb.key respectively.","title":"Prerequisites"},{"location":"installation/docker/prerequisites/#prerequisites","text":"In order to run the docker version of EVAdb in a secure and performant manner, some prerequisites need to be fulfilled. Please make sure that you have a basic understanding of docker and how the web works before setting up this website. In order to follow setup and usage guides, it is important that you have an understanding on docker, SSL certificates (for https) and the performance of the system you are hosting your database at.","title":"Prerequisites"},{"location":"installation/docker/prerequisites/#physical-infrastructure","text":"Hardware Requirements To be able to host EVAdb, the hardware must have: 4TB NVMe/SSD Storage Additional performance improvements are gained by utilizing more RAM and CPU Power. EVAdb is meant to host multiple thousand exome cases. As is the case with such datasets, even storing only variants will have the database growing to be multiple terabytes in size. In order to have a nice user experience for the frontend, it is important that the backend database does not bog down even for large requests (f.e. all autosomal dominant variants for one sample). To be able to scale the amount of data, we recommend a physical server utilizing NVMe (or at least SSD) storage technologies. This will greatly increase the database performance for all queries. Make sure you have enough storage available for the expected amount of data. The initialized application will consume around 400GB without any cases added. Spinning Rust We advise heavily against running the databse on older HDD type storage media. Performance will be abysmal.","title":"Physical Infrastructure"},{"location":"installation/docker/prerequisites/#docker","text":"Docker Docker is a isolation technique prevalent in modern software development since it allows the automatic deployment of complex software stacks. Read more: Docker Get Started Docker Setup To be able to host EVAdb through Docker Images, make sure you have installed and correctly configured: Docker docker-compose If you desire to install the application via Docker, please familiarize yourself with the basic concepts of Docker. To deploy the application, we use docker-compose which allows us to deploy the stack of multiple containers through use of a single command. Please follow the installation instructions for docker on your favorite operating system over at docker.com . Some operating systems might need additional setup after installation of docker, typically adding the active user to the docker group. Make sure you follow these steps as well (postinstallation) . To be able to continue with the installation guide, please also install docker-compose .","title":"Docker"},{"location":"installation/docker/prerequisites/#ssl-certificates","text":"SSL Certificates Obtaining a certificate and private key pair is necessary to host EVAdb. Make sure you have obtained a pair and named them evadb.crt and evadb.key to run the application. SSL is used in https to encrypt connections to remote servers. In order to validate the servers identity to the client, the server needs to present a valid certificate. Valid certificates can be obtained from letsencrypt or your local universities IT department. To run EVAdb, you have to supply a certificate for use by the web service. Letsencrypt In order to use the following letsencrypt description, your server needs to be reachable from the Internet and have a known DNS entry. In order to request a valid certificate from letsencrypt, you can use the certbot application. It can be installed on any UNIX-like machine through the package manager of choice. Once installed, use certbot certonly --standalone to get a certificate for your server. For development purposes, it is enough to create a self-signed certificate. On UNIX-like machines the openssl tool can be used to create a self-signed certificate for use with EVAdb. openssl req -x509 -newkey rsa:4096 \\ -keyout <KEY_NAME> \\ -out <CERT_NAME> \\ -days 365 \\ --nodes This will print your certificate and its private key at KEY_NAME and CERT_NAME respectively. To supply the certificate and private key to evadb, they have to be named evadb.crt and evadb.key respectively.","title":"SSL Certificates"},{"location":"installation/docker/run/","text":"Starting the Application After building the application, starting the whole stack is as simple as running the following command. docker-compose File All docker-compose based command lines need to be executed from the root directory of the application, where the docker-compose.yml is located. Otherwise you can rely on standard docker commands. Controling execution of the init container The behaviour of the init container can be controlled in a fine-grained manner by utilizing the different switches exposed as environment variables. For a first start, at least INIT_DB and INIT_USER have to be set to 1 . Additionally, we recommend setting IMPORT_CDSDB as otherwise the import process will not fully function. Make sure to unset INIT_DB and INIT_USER after the init container has run once. docker-compose up -d After some time, all containers will be started and isolated and your instance of EVAdb should be available at https://localhost:443/cgi-bin/login.pl and https://localhost:8443/cgi-bin/login.pl . If you are running on a remote server, you have to substitute localhost for the actual server name. If there are trouble getting a response from the server, you can use docker-compose logs [ -f ] [ CONTAINER_NAME ] to inspect the logs of all containers (if CONTAINER_NAME is omitted) or specific containers (supply the name). For further troubleshooting, it is possible to descend into the containers using the following commands. docker-compose exec [ CONTAINER_NAME ] [ TOOL ] # If the container is still running docker-compose run [ CONTAINER_NAME ] [ TOOL ] # If the container stopped To inspect the state of your container setup, please use docker-compose ps .","title":"First Start"},{"location":"installation/docker/run/#starting-the-application","text":"After building the application, starting the whole stack is as simple as running the following command. docker-compose File All docker-compose based command lines need to be executed from the root directory of the application, where the docker-compose.yml is located. Otherwise you can rely on standard docker commands. Controling execution of the init container The behaviour of the init container can be controlled in a fine-grained manner by utilizing the different switches exposed as environment variables. For a first start, at least INIT_DB and INIT_USER have to be set to 1 . Additionally, we recommend setting IMPORT_CDSDB as otherwise the import process will not fully function. Make sure to unset INIT_DB and INIT_USER after the init container has run once. docker-compose up -d After some time, all containers will be started and isolated and your instance of EVAdb should be available at https://localhost:443/cgi-bin/login.pl and https://localhost:8443/cgi-bin/login.pl . If you are running on a remote server, you have to substitute localhost for the actual server name. If there are trouble getting a response from the server, you can use docker-compose logs [ -f ] [ CONTAINER_NAME ] to inspect the logs of all containers (if CONTAINER_NAME is omitted) or specific containers (supply the name). For further troubleshooting, it is possible to descend into the containers using the following commands. docker-compose exec [ CONTAINER_NAME ] [ TOOL ] # If the container is still running docker-compose run [ CONTAINER_NAME ] [ TOOL ] # If the container stopped To inspect the state of your container setup, please use docker-compose ps .","title":"Starting the Application"},{"location":"installation/native/","text":"Native Installation Under Construction This part of the documentation is under construction In order to install the EVAdb Applications natively on a server, please see the Documentation in the main EVAdb repository","title":"Installation"},{"location":"installation/native/#native-installation","text":"Under Construction This part of the documentation is under construction In order to install the EVAdb Applications natively on a server, please see the Documentation in the main EVAdb repository","title":"Native Installation"}]}