{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Home Under Construction This documentation is under construction. Expect regular changes and updates or missing sections. Welcome to the documentation of EVAdb. The E xome V ariant A nalysis Database serves to streamline analysis of exome cases for the users. In this project we aim to provide a concise documentation for users and administrators of the software alike. Repositories All of EVAdb's source code and files necessary to run the application, can be found on github: EVAdb Pipeline EVAdb is in active use in Munich and Bonn. It has been developed by Tim Strom in Munich and has been used to analyze more than ten thousand exome case over the last years. It is based on perl scripts and a MySQL database. It can be installed directly on bare-matel or a VM or build and deployed via docker. Content Installation Setup and Configuration Maintainance Data Upload Usage","title":"Home"},{"location":"#home","text":"Under Construction This documentation is under construction. Expect regular changes and updates or missing sections. Welcome to the documentation of EVAdb. The E xome V ariant A nalysis Database serves to streamline analysis of exome cases for the users. In this project we aim to provide a concise documentation for users and administrators of the software alike. Repositories All of EVAdb's source code and files necessary to run the application, can be found on github: EVAdb Pipeline EVAdb is in active use in Munich and Bonn. It has been developed by Tim Strom in Munich and has been used to analyze more than ten thousand exome case over the last years. It is based on perl scripts and a MySQL database. It can be installed directly on bare-matel or a VM or build and deployed via docker.","title":"Home"},{"location":"#content","text":"Installation Setup and Configuration Maintainance Data Upload Usage","title":"Content"},{"location":"architecture/","text":"Software Architecture EVAdb is built as a collection of perl modules on top of a MySQL database. It can be split logically into three big parts: EVAdb The main user-facing application for variant filtration, annotation. This part will be most often used by normal users aiming to gain insights into their datasets. Admin Application The admin application is the backend of EVAdb. It can be used to create samples as well as managing data access permissions and relationships between groups of or individual samples. Solexa Lims System EVAdb also features a LIMS system for use by wet lab groups. Through this interface, additional information for samples can be provided. Most of the information relating to this part of the application is retrieved from the dna extraction and sequencing processes. We provide setup and usage guides for EVAdb and the Admin Application here. EVAdb The main user interface of the application. With the user interface provided by this application users are able to filter variants based on pre-defined strategies such as autosomal dominant (among others). Admin Application The admin application is used to set meta data and permissions for individual or groups of samples. Selected users should have access to this part of the application to manage sample ingress and curate the available data.","title":"Software Architecture"},{"location":"architecture/#software-architecture","text":"EVAdb is built as a collection of perl modules on top of a MySQL database. It can be split logically into three big parts: EVAdb The main user-facing application for variant filtration, annotation. This part will be most often used by normal users aiming to gain insights into their datasets. Admin Application The admin application is the backend of EVAdb. It can be used to create samples as well as managing data access permissions and relationships between groups of or individual samples. Solexa Lims System EVAdb also features a LIMS system for use by wet lab groups. Through this interface, additional information for samples can be provided. Most of the information relating to this part of the application is retrieved from the dna extraction and sequencing processes. We provide setup and usage guides for EVAdb and the Admin Application here.","title":"Software Architecture"},{"location":"architecture/#evadb","text":"The main user interface of the application. With the user interface provided by this application users are able to filter variants based on pre-defined strategies such as autosomal dominant (among others).","title":"EVAdb"},{"location":"architecture/#admin-application","text":"The admin application is used to set meta data and permissions for individual or groups of samples. Selected users should have access to this part of the application to manage sample ingress and curate the available data.","title":"Admin Application"},{"location":"administration/annotation/","text":"Variant Annotation To upload a vcf file, first it must be annotated using a custom perl pipeline. Docker The following documentation is specific to the Docker version of EVAdb. When using the bare-metal installation your mileage may vary, the general steps remain the same however. VEP It is intended to switch from the custom annotation pipeline to VEP . This documentation will be update accordingly. Annotation is performed at the same time as the actual data upload. For this, we use a set of intermittent annotation and insert steps. Each step performs annotation for things like genes and transcripts based on data from the annotation tables present in the database. For ease of use, the annotation container uses the main script externalPipelineImport.pl as entrypoint interface. To start the import process, the script needs access to a vcf file, the sample id of the sample in the database and the settings name ( hg19_plus ). References with/without chr tags Depending on the Reference that you use for variant calling and alignment, the contigs will be either have the chr prefix (e.g. chr1 ), or not (e.g. 1 ). EVAdb uses the UCSC versions of all contigs, so the prefix must be present. Data Paths The paths to your data most likely differ between the container and the outside world. Make sure to adjust the paths for your mountpoint ( the DATA_DIR configuration variable). Data is mounted to /data inside the container. To import a single or multi-sample vcf file, the following command line is sufficient. docker-compose run annotation -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus Inside the container If you want to open a shell inside the annotation container first, the command can be run as: docker-compose run annotation bash # or the corresponding docker exec perl /pipeline/externalPipelineImport.pl -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus The externalPipelineImport.pl draws most of its runtime information off the current.config.xml file. If you do run on bare-metal make sure to set the paths in this file such that tool directories and data locations are what is required by the tool. Data Locality With the current iteration of EVAdb and the Docker images all data must be local to the EVAdb server. As noticed in the configuration part , all data directories are entered as docker volume and put through to the container. As such, the data paths differ between container and host. Nevertheless, it is not currently possible to upload samples or data from remote hosts to the machine in excess of what is possible through the use of the web interface. We recommend a data partition or disk with enough storage for your NGS experiments to host this data. This brings two advantages, first you spare the database disk from additional stress (it will be under heavy load on sample import) and additionally you can use cheaper mass storage media to host the bulk (e.g. .bam or .fq.gz ) of your data. Scripts importVCF.sh To upload many samples in quick succession, we use the following script. Breakage - Adjust before use This script is provided as an example for a complete import process. As it is written with the specific configuration of our site in mind it will most likely not work without changes on other systems. #! /bin/bash # vim: ts=4 sw=4 expandtab EVADB_DIR = \"/home/evadb\" INPUT_DIR = \"/gluster/gluster01/share/exome\" function usage { echo -e \"importVCF.sh\\n\\nImport all VCFs of a given Flow Cell into the EVAdb running in $EVADB_DIR as\\ndocker version. Files are searched for in $INPUT_DIR .\\n\\nParameters:\\n\\n\\t-f\\t\\tFlow Cell to import.\\n\\t-h\\t\\tPrint help.\" } PW_FILE = \"/home/evadb/.env\" ROOT_PW = $( grep MYSQL_ROOT_PASSWORD $PW_FILE | cut -d \"=\" -f2 ) while getopts \"f:h\" arg ; do case $arg in f ) FLOW_CELL = \" ${ OPTARG } \" ;; h ) usage exit 0 ;; esac done if [ -z \" $FLOW_CELL \" ] ; then echo -e \"Error: Please supply a flow cell id.\" usage exit 1 fi echo -e \"Searching $INPUT_DIR / $FLOW_CELL /\" ESC_INPUT = $( echo \" ${ INPUT_DIR } \" | sed -e 's/[](&|$|\\|{|}).*[\\^]/\\\\&/g' ) cd $EVADB_DIR for f in $( find \" $INPUT_DIR / $FLOW_CELL /\" -name \"DE*vcf.gz\" ) do BASENAME = $( basename $f ) DIRNAME = $( dirname $f ) SAMPLE = ${ BASENAME %%.* } VCF = \" $DIRNAME / $SAMPLE .chr.vcf\" QUERY = \"select * from sample where name LIKE '% $SAMPLE %' or pedigree LIKE '% $SAMPLE %' or foreignid LIKE '% $SAMPLE %';\" SAMPLE_IN_DB = $( docker-compose exec db mysql -u root -p $ROOT_PW -e \" $QUERY \" exomehg19 | grep \" $SAMPLE \" ) if [[ -n \" $SAMPLE_IN_DB \" ]] ; then echo \"Annotating and Importing $SAMPLE ..\" echo -e \"\\tAdding chr prefix...\" zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF echo -e \"\\tImporting $SAMPLE into evadb...\" docker-compose run annotation -vcf \" ${ VCF / $ESC_INPUT / \\/ data } \" -sample \" $SAMPLE \" -se hg19_plus echo -e \"\\tCleanup...\" rm $VCF else echo -e \"Could not find $SAMPLE in database. Have you create the sample using \\\"Import external samples\\\"?\" fi done cd -","title":"Variant Annotation and Upload"},{"location":"administration/annotation/#variant-annotation","text":"To upload a vcf file, first it must be annotated using a custom perl pipeline. Docker The following documentation is specific to the Docker version of EVAdb. When using the bare-metal installation your mileage may vary, the general steps remain the same however. VEP It is intended to switch from the custom annotation pipeline to VEP . This documentation will be update accordingly. Annotation is performed at the same time as the actual data upload. For this, we use a set of intermittent annotation and insert steps. Each step performs annotation for things like genes and transcripts based on data from the annotation tables present in the database. For ease of use, the annotation container uses the main script externalPipelineImport.pl as entrypoint interface. To start the import process, the script needs access to a vcf file, the sample id of the sample in the database and the settings name ( hg19_plus ). References with/without chr tags Depending on the Reference that you use for variant calling and alignment, the contigs will be either have the chr prefix (e.g. chr1 ), or not (e.g. 1 ). EVAdb uses the UCSC versions of all contigs, so the prefix must be present. Data Paths The paths to your data most likely differ between the container and the outside world. Make sure to adjust the paths for your mountpoint ( the DATA_DIR configuration variable). Data is mounted to /data inside the container. To import a single or multi-sample vcf file, the following command line is sufficient. docker-compose run annotation -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus Inside the container If you want to open a shell inside the annotation container first, the command can be run as: docker-compose run annotation bash # or the corresponding docker exec perl /pipeline/externalPipelineImport.pl -vcf <VCF_FILE> \\ -sample \"<SAMPLE>\" \\ -se hg19_plus The externalPipelineImport.pl draws most of its runtime information off the current.config.xml file. If you do run on bare-metal make sure to set the paths in this file such that tool directories and data locations are what is required by the tool.","title":"Variant Annotation"},{"location":"administration/annotation/#data-locality","text":"With the current iteration of EVAdb and the Docker images all data must be local to the EVAdb server. As noticed in the configuration part , all data directories are entered as docker volume and put through to the container. As such, the data paths differ between container and host. Nevertheless, it is not currently possible to upload samples or data from remote hosts to the machine in excess of what is possible through the use of the web interface. We recommend a data partition or disk with enough storage for your NGS experiments to host this data. This brings two advantages, first you spare the database disk from additional stress (it will be under heavy load on sample import) and additionally you can use cheaper mass storage media to host the bulk (e.g. .bam or .fq.gz ) of your data.","title":"Data Locality"},{"location":"administration/annotation/#scripts","text":"","title":"Scripts"},{"location":"administration/annotation/#importvcfsh","text":"To upload many samples in quick succession, we use the following script. Breakage - Adjust before use This script is provided as an example for a complete import process. As it is written with the specific configuration of our site in mind it will most likely not work without changes on other systems. #! /bin/bash # vim: ts=4 sw=4 expandtab EVADB_DIR = \"/home/evadb\" INPUT_DIR = \"/gluster/gluster01/share/exome\" function usage { echo -e \"importVCF.sh\\n\\nImport all VCFs of a given Flow Cell into the EVAdb running in $EVADB_DIR as\\ndocker version. Files are searched for in $INPUT_DIR .\\n\\nParameters:\\n\\n\\t-f\\t\\tFlow Cell to import.\\n\\t-h\\t\\tPrint help.\" } PW_FILE = \"/home/evadb/.env\" ROOT_PW = $( grep MYSQL_ROOT_PASSWORD $PW_FILE | cut -d \"=\" -f2 ) while getopts \"f:h\" arg ; do case $arg in f ) FLOW_CELL = \" ${ OPTARG } \" ;; h ) usage exit 0 ;; esac done if [ -z \" $FLOW_CELL \" ] ; then echo -e \"Error: Please supply a flow cell id.\" usage exit 1 fi echo -e \"Searching $INPUT_DIR / $FLOW_CELL /\" ESC_INPUT = $( echo \" ${ INPUT_DIR } \" | sed -e 's/[](&|$|\\|{|}).*[\\^]/\\\\&/g' ) cd $EVADB_DIR for f in $( find \" $INPUT_DIR / $FLOW_CELL /\" -name \"DE*vcf.gz\" ) do BASENAME = $( basename $f ) DIRNAME = $( dirname $f ) SAMPLE = ${ BASENAME %%.* } VCF = \" $DIRNAME / $SAMPLE .chr.vcf\" QUERY = \"select * from sample where name LIKE '% $SAMPLE %' or pedigree LIKE '% $SAMPLE %' or foreignid LIKE '% $SAMPLE %';\" SAMPLE_IN_DB = $( docker-compose exec db mysql -u root -p $ROOT_PW -e \" $QUERY \" exomehg19 | grep \" $SAMPLE \" ) if [[ -n \" $SAMPLE_IN_DB \" ]] ; then echo \"Annotating and Importing $SAMPLE ..\" echo -e \"\\tAdding chr prefix...\" zcat $f | awk '{ if ( $1 ~ \"#\" ) { print $0 } else { print \"chr\"$0 } }' > $VCF echo -e \"\\tImporting $SAMPLE into evadb...\" docker-compose run annotation -vcf \" ${ VCF / $ESC_INPUT / \\/ data } \" -sample \" $SAMPLE \" -se hg19_plus echo -e \"\\tCleanup...\" rm $VCF else echo -e \"Could not find $SAMPLE in database. Have you create the sample using \\\"Import external samples\\\"?\" fi done cd -","title":"importVCF.sh"},{"location":"administration/disease/","text":"Diseases and Disease Groups","title":"Diseases and Disease Groups"},{"location":"administration/disease/#diseases-and-disease-groups","text":"","title":"Diseases and Disease Groups"},{"location":"administration/project/","text":"Projects and Cooperations","title":"Projects and Cooperations"},{"location":"administration/project/#projects-and-cooperations","text":"","title":"Projects and Cooperations"},{"location":"administration/quick-start/","text":"Administration Guide - Quick Start","title":"Quick Start"},{"location":"administration/quick-start/#administration-guide-quick-start","text":"","title":"Administration Guide - Quick Start"},{"location":"administration/sample/","text":"Sample Management Samples are central to every analysis. For every query, a sample needs to be submitted which is used to filter the variants. All SNV's are associated with one or more sample. A family is denoted by a pedigree id. Filling out sample and pedigree information is prerequisite to the other data upload scripts and can be achieved using a pre-formatted sample sheet. Sample Management To add new samples to the system, please follow the following procedure: Create a sample sheet ( Example ) Upload the sample sheet through \"Import External Data\" Add family information for each sample Sample Sheets A sample sheet can be created as a basic comma separated file. The following columns are mandatory. Column Description Sample ID Unique sample identifier Foreign ID Secondary sample identifier (f.e. external IDs) Pedigree Family id denoting members of one family Comment Arbitrary comment Sex Sex of the patient (\"male\" or \"female\") Affected Affectedness (0/1) Organism Sequenced organism Tissue Tissue that was sequenced (peripheral blood etc.) Disease A name of a disease (must exist in the database) Library Type Sequencing library type Read Type Library sequencing protocol type Exome Assay Exome capture kit used for sequencing Example Sample Sheet Table Sample ID Foreign ID Pedigree Comment Sex Affected Organism Tissue Disease Library Type Read Type Exome Assay 76436 76436 B20-0498 TranslateNamse female 1 human peripheral blood Cases exomic paired-end SureSelect60Mbv6 76443 76443 B20-0498 TranslateNamse male 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 76442 76442 B20-0498 TranslateNamse female 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 .csv File Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 Entering Family Information While the pedigree ID for each sample can be specified in the sample sheet, the precise family structure can not. For this it is necessary to go through the manual process using the UI. To add family information to a sample, you have to use the admin application. In the admin application, use the following procedure to add the pedigree information (i.e. father/mother). Find the sample using Search samples Click on the Id column of the sample you want to modify Enter mother and father in the corresponding rows","title":"Sample Management"},{"location":"administration/sample/#sample-management","text":"Samples are central to every analysis. For every query, a sample needs to be submitted which is used to filter the variants. All SNV's are associated with one or more sample. A family is denoted by a pedigree id. Filling out sample and pedigree information is prerequisite to the other data upload scripts and can be achieved using a pre-formatted sample sheet. Sample Management To add new samples to the system, please follow the following procedure: Create a sample sheet ( Example ) Upload the sample sheet through \"Import External Data\" Add family information for each sample","title":"Sample Management"},{"location":"administration/sample/#sample-sheets","text":"A sample sheet can be created as a basic comma separated file. The following columns are mandatory. Column Description Sample ID Unique sample identifier Foreign ID Secondary sample identifier (f.e. external IDs) Pedigree Family id denoting members of one family Comment Arbitrary comment Sex Sex of the patient (\"male\" or \"female\") Affected Affectedness (0/1) Organism Sequenced organism Tissue Tissue that was sequenced (peripheral blood etc.) Disease A name of a disease (must exist in the database) Library Type Sequencing library type Read Type Library sequencing protocol type Exome Assay Exome capture kit used for sequencing","title":"Sample Sheets"},{"location":"administration/sample/#example-sample-sheet","text":"","title":"Example Sample Sheet"},{"location":"administration/sample/#table","text":"Sample ID Foreign ID Pedigree Comment Sex Affected Organism Tissue Disease Library Type Read Type Exome Assay 76436 76436 B20-0498 TranslateNamse female 1 human peripheral blood Cases exomic paired-end SureSelect60Mbv6 76443 76443 B20-0498 TranslateNamse male 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6 76442 76442 B20-0498 TranslateNamse female 0 human peripheral blood Controls exomic paired-end SureSelect60Mbv6","title":"Table"},{"location":"administration/sample/#csv-file","text":"Sample ID,Foreign ID,Pedigree,Comment,Sex,Affected,Organism,Tissue,Disease,Library Type,Read Type,Exome Assay 76436,76436,B20-0498,TranslateNamse,female,1,human,peripheral blood,Cases,exomic,paired-end,SureSelect60Mbv6 76443,76443,B20-0498,TranslateNamse,male,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6 76442,76442,B20-0498,TranslateNamse,female,0,human,peripheral blood,Controls,exomic,paired-end,SureSelect60Mbv6","title":".csv File"},{"location":"administration/sample/#entering-family-information","text":"While the pedigree ID for each sample can be specified in the sample sheet, the precise family structure can not. For this it is necessary to go through the manual process using the UI. To add family information to a sample, you have to use the admin application. In the admin application, use the following procedure to add the pedigree information (i.e. father/mother). Find the sample using Search samples Click on the Id column of the sample you want to modify Enter mother and father in the corresponding rows","title":"Entering Family Information"},{"location":"administration/user/","text":"User Management","title":"User Management"},{"location":"administration/user/#user-management","text":"","title":"User Management"},{"location":"installation/docker/build/","text":"Docker Container Docker Container The application, as presented, utilizes multiple docker containers for the components. mariadb EVAdb (docker/snv-hg19p) EVAdb admin (docker/snvedit) init container (helperscripts) annotation (annotation) The EVAdb application consists of two user-facing web interfaces hosted through an Apache Webserver as cgi scripts. To run the application, we also setup the mysql database (mariadb), an init container and an annotation container. The primary use-case of the init container is creation of the database, initial user setup and import of external databases. It should be run on first startup and whenever external data needs changing. The annotation container is intended to be used for the import of vcf files from your standard GATK best practices pipeline. The setup of all containers is done through the docker-compose script ( docker-compose.yml ). Below, we will explain the basic setup of each containers. docker-compose run To execute a tool in a running container of our setup, please use either docker-compose exec [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently running, or docker-compose run [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently shut off. For example, to inspect the database in detail, one can use docker-compose exec db mysql -u <USER> -p<PW> to get a mysql shell in the container. EVAdb and EVAdb Admin Containers Both containers are extended from standard apache/httpd Dockerfiles. We support some environment variables to supply the database user and password data. For each container, the application will run as https web service on port 443 which can be forwarded by standard docker syntax. By default, the user facing filter application will take port 443 of the host and the admin application will use port 8443. Firewall Setup When running a production setup where access to your EVAdb instance from the internet is required it is recommended to run a firewall with only port 443 accessible from the outside. In such a setup, you could access the admin backend only from your local network or through SSH port-forwarding (f.e.) SSL Setup Both containers require a docker volume to be mounted at the /ssl location (can be read-only) containing a certificate and private key file for the SSL connection. The files must be named evadb.crt and evadb.key respectively. Init Container The init container will initialize the database. It creates the first user for the web interface which can then create other users as well. It is built from a standard debian image and installs most software for running the perl scripts to setup the database. It features two docker-volumes which need to be populated with data for the container to work properly. Volume Purpose /library Hosting pre-downloaded external databases (gnomAD, dbNSFP etc.). See the Download Section for more details. /database Database dumps and sql scripts for database creation. The container uses all scripts from this folder to initialize the database. The behaviour of the container can be influenced by setting the IMPORT_* and INIT_* environment variables. This is especially useful if only a single third-party dataset should be reimported. Other values than 1 (e.g. 0 ) will turn off the respective part. Database Wipe If the Init container is run with INIT_DB=1 on an initialized database all data is wiped off the installation. Setting Default Description INIT_DB 1 Initialize (wipes existing data) the database INIT_USER 1 Setup admin user and password IMPORT_DBNSFP 1 Toggle import of Polyphen2 and SIFT IMPORT_CADD 1 Toggle import of CADD scores IMPORT_GNOMAD 1 Toggle import of gnomAD IMPORT_DGV 1 Toggle import of dgv structural variation IMPORT_CLINVAR 1 Toggle import of clinvar data IMPORT_UCSC 1 Toggle import of ucsc data IMPORT_CDSDB 1 Toggle import of coding sequence database IMPORT_LOF_METRICS 1 Toggle import of gnomad scores by gene Annotation Container The annotation container is built from the ngs-pipeline repository. Its primary purpose is enabling the import of vcf files for samples. For this, it uses the externalPipelineImport.pl tool as its main interface via entrypoint.sh . Data should be provided via the volume /data . The container expects library data (such as human reference genomes) at /library and databases for annotation at /anno_db . How to use this container to import a VCF file will be described in another section. Build Before the application can be started, application containers have to be built. This can be achieved with the following command. docker-compose build Time Building these containers will take some time. Especially the init and annotation containers have to install a lot of perl modules and take some time before they are ready.","title":"Build"},{"location":"installation/docker/build/#docker-container","text":"Docker Container The application, as presented, utilizes multiple docker containers for the components. mariadb EVAdb (docker/snv-hg19p) EVAdb admin (docker/snvedit) init container (helperscripts) annotation (annotation) The EVAdb application consists of two user-facing web interfaces hosted through an Apache Webserver as cgi scripts. To run the application, we also setup the mysql database (mariadb), an init container and an annotation container. The primary use-case of the init container is creation of the database, initial user setup and import of external databases. It should be run on first startup and whenever external data needs changing. The annotation container is intended to be used for the import of vcf files from your standard GATK best practices pipeline. The setup of all containers is done through the docker-compose script ( docker-compose.yml ). Below, we will explain the basic setup of each containers. docker-compose run To execute a tool in a running container of our setup, please use either docker-compose exec [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently running, or docker-compose run [ db | evadb_user | evadb_admin | evadb_init | annotation ] bash if the container is currently shut off. For example, to inspect the database in detail, one can use docker-compose exec db mysql -u <USER> -p<PW> to get a mysql shell in the container.","title":"Docker Container"},{"location":"installation/docker/build/#evadb-and-evadb-admin-containers","text":"Both containers are extended from standard apache/httpd Dockerfiles. We support some environment variables to supply the database user and password data. For each container, the application will run as https web service on port 443 which can be forwarded by standard docker syntax. By default, the user facing filter application will take port 443 of the host and the admin application will use port 8443. Firewall Setup When running a production setup where access to your EVAdb instance from the internet is required it is recommended to run a firewall with only port 443 accessible from the outside. In such a setup, you could access the admin backend only from your local network or through SSH port-forwarding (f.e.) SSL Setup Both containers require a docker volume to be mounted at the /ssl location (can be read-only) containing a certificate and private key file for the SSL connection. The files must be named evadb.crt and evadb.key respectively.","title":"EVAdb and EVAdb Admin Containers"},{"location":"installation/docker/build/#init-container","text":"The init container will initialize the database. It creates the first user for the web interface which can then create other users as well. It is built from a standard debian image and installs most software for running the perl scripts to setup the database. It features two docker-volumes which need to be populated with data for the container to work properly. Volume Purpose /library Hosting pre-downloaded external databases (gnomAD, dbNSFP etc.). See the Download Section for more details. /database Database dumps and sql scripts for database creation. The container uses all scripts from this folder to initialize the database. The behaviour of the container can be influenced by setting the IMPORT_* and INIT_* environment variables. This is especially useful if only a single third-party dataset should be reimported. Other values than 1 (e.g. 0 ) will turn off the respective part. Database Wipe If the Init container is run with INIT_DB=1 on an initialized database all data is wiped off the installation. Setting Default Description INIT_DB 1 Initialize (wipes existing data) the database INIT_USER 1 Setup admin user and password IMPORT_DBNSFP 1 Toggle import of Polyphen2 and SIFT IMPORT_CADD 1 Toggle import of CADD scores IMPORT_GNOMAD 1 Toggle import of gnomAD IMPORT_DGV 1 Toggle import of dgv structural variation IMPORT_CLINVAR 1 Toggle import of clinvar data IMPORT_UCSC 1 Toggle import of ucsc data IMPORT_CDSDB 1 Toggle import of coding sequence database IMPORT_LOF_METRICS 1 Toggle import of gnomad scores by gene","title":"Init Container"},{"location":"installation/docker/build/#annotation-container","text":"The annotation container is built from the ngs-pipeline repository. Its primary purpose is enabling the import of vcf files for samples. For this, it uses the externalPipelineImport.pl tool as its main interface via entrypoint.sh . Data should be provided via the volume /data . The container expects library data (such as human reference genomes) at /library and databases for annotation at /anno_db . How to use this container to import a VCF file will be described in another section.","title":"Annotation Container"},{"location":"installation/docker/build/#build","text":"Before the application can be started, application containers have to be built. This can be achieved with the following command. docker-compose build Time Building these containers will take some time. Especially the init and annotation containers have to install a lot of perl modules and take some time before they are ready.","title":"Build"},{"location":"installation/docker/configuration/","text":"Configuration The original software of EVAdb is not very configurable and does not feature any dedicated configuration files. Therefore, the options for configuration are very limited. Nevertheless all of the following parameters should be set in your docker .env file prior to build time. Docker .env Make sure you understand the basics behind docker environment variables and how the .env file fits in. Read more: Environment variables in Compose The following parameters are available to be configured. Please also see the example file at the end of this section. Setting Description Example MYSQL_ROOT_PASSWORD Password of the mysql root user sup3rs3cur3 MYSQL_PASSWORD Password for the mysql user myPass MYSQL_USER Username for the mysql account evadb MYSQL_DATABASE Standard mysql database solexa YUBIKEY_ID Yubikey ID (if present) test YUBIKEY_APIKEY Yubikey api key secr3t DATABASE_DIR Persistent database storage dir /big_storage CURRENT_UID UID and GID to run the database with normal user permissions 1000:1000 CERT_DIR Directory where certificates are stored /secrets INITIAL_USER Initial evadb user name admin INITIAL_USER_PASSWD Password for the initial evadb user abc123 ANNO_DB_DIR Location of annotation databases (gnomAD, dbNSFP etc.) /anno_db LIBRARY Location for library files (reference genomes etc.) /reference DATA_DIR Directory containing data files for upload (vcf etc.) /data Example .env File Setting CURRENT_UID To set the CURRENT_UID parameter for your own user, use the result of the command: echo \" $( id -u ) : $( id -g ) \" The following is an example .env file. MYSQL_ROOT_PASSWORD = root_pw MYSQL_PASSWORD = user_pass MYSQL_USER = evadb MYSQL_DATABASE = solexa YUBIKEY_ID = test YUBIKEY_APIKEY = secr3t DATABASE_DIR = /evadb CURRENT_UID = 1000 :1000 CERT_DIR = /home/evadb/secrets/ INITIAL_USER = admin INITIAL_USER_PASSWD = admin_pw ANNO_DB_DIR = /annotation_db/ LIBRARY = /library/ DATA_DIR = /data/","title":"Configuration"},{"location":"installation/docker/configuration/#configuration","text":"The original software of EVAdb is not very configurable and does not feature any dedicated configuration files. Therefore, the options for configuration are very limited. Nevertheless all of the following parameters should be set in your docker .env file prior to build time. Docker .env Make sure you understand the basics behind docker environment variables and how the .env file fits in. Read more: Environment variables in Compose The following parameters are available to be configured. Please also see the example file at the end of this section. Setting Description Example MYSQL_ROOT_PASSWORD Password of the mysql root user sup3rs3cur3 MYSQL_PASSWORD Password for the mysql user myPass MYSQL_USER Username for the mysql account evadb MYSQL_DATABASE Standard mysql database solexa YUBIKEY_ID Yubikey ID (if present) test YUBIKEY_APIKEY Yubikey api key secr3t DATABASE_DIR Persistent database storage dir /big_storage CURRENT_UID UID and GID to run the database with normal user permissions 1000:1000 CERT_DIR Directory where certificates are stored /secrets INITIAL_USER Initial evadb user name admin INITIAL_USER_PASSWD Password for the initial evadb user abc123 ANNO_DB_DIR Location of annotation databases (gnomAD, dbNSFP etc.) /anno_db LIBRARY Location for library files (reference genomes etc.) /reference DATA_DIR Directory containing data files for upload (vcf etc.) /data","title":"Configuration"},{"location":"installation/docker/configuration/#example-env-file","text":"Setting CURRENT_UID To set the CURRENT_UID parameter for your own user, use the result of the command: echo \" $( id -u ) : $( id -g ) \" The following is an example .env file. MYSQL_ROOT_PASSWORD = root_pw MYSQL_PASSWORD = user_pass MYSQL_USER = evadb MYSQL_DATABASE = solexa YUBIKEY_ID = test YUBIKEY_APIKEY = secr3t DATABASE_DIR = /evadb CURRENT_UID = 1000 :1000 CERT_DIR = /home/evadb/secrets/ INITIAL_USER = admin INITIAL_USER_PASSWD = admin_pw ANNO_DB_DIR = /annotation_db/ LIBRARY = /library/ DATA_DIR = /data/","title":"Example .env File"},{"location":"installation/docker/download/","text":"Download To be able to build and run the software, we first need to download the scripts and binary files. Additionally to have a fully functioning EVAdb many third-party datasets should also be downloaded. Data from gnomAD , dbSNP and others is used in many filtering steps to find rare variants or variants associated with the given phenotype of the patient. After downloading the scripts and Dockerfiles, we will build the container images. Are pre-built Docker containers available for EVAdb? Currently, the Docker containers for EVAdb are not available on a public docker registry. Therefore, the images must be built on a local machine before use. EVAdb All files necessary to deploy EVAdb can be found in the git repository of EVAdb ( here ). The docker branch contains Dockerfiles and docker-compose scripts for building and installing the software. Proxy If youre locked behind a restrictive proxy that you need to access the internet from your build host you have to adapt the Dockerfiles. Currently, it is necessary to set the http_proxy and https_proxy environment variables. # Prefix each Dockerfile with ENV http_proxy http://<USER>:<PW>@<IP>:<PORT>/ ENV https_proxy http://<USER>:<PW>@<IP>:<PORT>/ RUN git config --global https.proxy ${ https_proxy } \\ && git config --global http.proxy ${ http_proxy } \\ && git config --global https.proxyAuthMethod basic \\ && git config --global http.proxyAuthMethod basic To clone the EVAdb docker branch, use git clone -b docker https://github.com/mri-ihg/EVAdb.git Third-Party Data When building the container images and on first startup of the application, it is recommended to have some third party datasets available. It is possible to run the application without this data for development purposes, but in a production setup these datasets should be present in order for all features to work as expected (f.e. gnomAD filtering). hg19 vs GRCh38 All library file URL's have to be adjusted for hg38 If you intend to process hg38 with the current version of EVAdb, make sure to include the correct library files. All URL's in the table below are for hg19 . Dataset Storage Some of the datasets are very large. gnomAD genomes for example exceeds 200GB in size. Make sure to have enough disk space available when downloading these assets. Dataset Description URL dbNSFP Polyphen2 and SIFT scores are taken from dbNSFP ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFPv3.5a.zip CADD Cadd scores https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh37/whole_genome_SNVs.tsv.gz gnomAD Genome aggregation database Exome and Genome builds https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.vcf.bgz OMIM Mendelian inheritance in men Request individual acces at omim.org","title":"Download"},{"location":"installation/docker/download/#download","text":"To be able to build and run the software, we first need to download the scripts and binary files. Additionally to have a fully functioning EVAdb many third-party datasets should also be downloaded. Data from gnomAD , dbSNP and others is used in many filtering steps to find rare variants or variants associated with the given phenotype of the patient. After downloading the scripts and Dockerfiles, we will build the container images. Are pre-built Docker containers available for EVAdb? Currently, the Docker containers for EVAdb are not available on a public docker registry. Therefore, the images must be built on a local machine before use.","title":"Download"},{"location":"installation/docker/download/#evadb","text":"All files necessary to deploy EVAdb can be found in the git repository of EVAdb ( here ). The docker branch contains Dockerfiles and docker-compose scripts for building and installing the software. Proxy If youre locked behind a restrictive proxy that you need to access the internet from your build host you have to adapt the Dockerfiles. Currently, it is necessary to set the http_proxy and https_proxy environment variables. # Prefix each Dockerfile with ENV http_proxy http://<USER>:<PW>@<IP>:<PORT>/ ENV https_proxy http://<USER>:<PW>@<IP>:<PORT>/ RUN git config --global https.proxy ${ https_proxy } \\ && git config --global http.proxy ${ http_proxy } \\ && git config --global https.proxyAuthMethod basic \\ && git config --global http.proxyAuthMethod basic To clone the EVAdb docker branch, use git clone -b docker https://github.com/mri-ihg/EVAdb.git","title":"EVAdb"},{"location":"installation/docker/download/#third-party-data","text":"When building the container images and on first startup of the application, it is recommended to have some third party datasets available. It is possible to run the application without this data for development purposes, but in a production setup these datasets should be present in order for all features to work as expected (f.e. gnomAD filtering). hg19 vs GRCh38 All library file URL's have to be adjusted for hg38 If you intend to process hg38 with the current version of EVAdb, make sure to include the correct library files. All URL's in the table below are for hg19 . Dataset Storage Some of the datasets are very large. gnomAD genomes for example exceeds 200GB in size. Make sure to have enough disk space available when downloading these assets. Dataset Description URL dbNSFP Polyphen2 and SIFT scores are taken from dbNSFP ftp://dbnsfp:dbnsfp@dbnsfp.softgenetics.com/dbNSFPv3.5a.zip CADD Cadd scores https://krishna.gs.washington.edu/download/CADD/v1.6/GRCh37/whole_genome_SNVs.tsv.gz gnomAD Genome aggregation database Exome and Genome builds https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/exomes/gnomad.exomes.r2.1.1.sites.vcf.bgz https://storage.googleapis.com/gnomad-public/release/2.1.1/vcf/genomes/gnomad.genomes.r2.1.1.sites.vcf.bgz OMIM Mendelian inheritance in men Request individual acces at omim.org","title":"Third-Party Data"},{"location":"installation/docker/prerequisites/","text":"Prerequisites In order to run the docker version of EVAdb in a secure and performant manner, some prerequisites need to be fulfilled. Please make sure that you have a basic understanding of docker and how the web works before setting up this website. In order to follow setup and usage guides, it is important that you have an understanding on docker, SSL certificates (for https) and the performance of the system you are hosting your database at. Physical Infrastructure Hardware Requirements To be able to host EVAdb, the hardware must have: 4TB NVMe/SSD Storage Additional performance improvements are gained by utilizing more RAM and CPU Power. EVAdb is meant to host multiple thousand exome cases. As is the case with such datasets, even storing only variants will have the database growing to be multiple terabytes in size. In order to have a nice user experience for the frontend, it is important that the backend database does not bog down even for large requests (f.e. all autosomal dominant variants for one sample). To be able to scale the amount of data, we recommend a physical server utilizing NVMe (or at least SSD) storage technologies. This will greatly increase the database performance for all queries. Make sure you have enough storage available for the expected amount of data. The initialized application will consume around 400GB without any cases added. Spinning Rust We advise heavily against running the databse on older HDD type storage media. Performance will be abysmal. Docker Docker Docker is a isolation technique prevalent in modern software development since it allows the automatic deployment of complex software stacks. Read more: Docker Get Started Docker Setup To be able to host EVAdb through Docker Images, make sure you have installed and correctly configured: Docker docker-compose If you desire to install the application via Docker, please familiarize yourself with the basic concepts of Docker. To deploy the application, we use docker-compose which allows us to deploy the stack of multiple containers through use of a single command. Please follow the installation instructions for docker on your favorite operating system over at docker.com . Some operating systems might need additional setup after installation of docker, typically adding the active user to the docker group. Make sure you follow these steps as well (postinstallation) . To be able to continue with the installation guide, please also install docker-compose . SSL Certificates SSL Certificates Obtaining a certificate and private key pair is necessary to host EVAdb. Make sure you have obtained a pair and named them evadb.crt and evadb.key to run the application. SSL is used in https to encrypt connections to remote servers. In order to validate the servers identity to the client, the server needs to present a valid certificate. Valid certificates can be obtained from letsencrypt or your local universities IT department. To run EVAdb, you have to supply a certificate for use by the web service. Letsencrypt In order to use the following letsencrypt description, your server needs to be reachable from the Internet and have a known DNS entry. In order to request a valid certificate from letsencrypt, you can use the certbot application. It can be installed on any UNIX-like machine through the package manager of choice. Once installed, use certbot certonly --standalone to get a certificate for your server. For development purposes, it is enough to create a self-signed certificate. On UNIX-like machines the openssl tool can be used to create a self-signed certificate for use with EVAdb. openssl req -x509 -newkey rsa:4096 \\ -keyout <KEY_NAME> \\ -out <CERT_NAME> \\ -days 365 \\ --nodes This will print your certificate and its private key at KEY_NAME and CERT_NAME respectively. To supply the certificate and private key to evadb, they have to be named evadb.crt and evadb.key respectively.","title":"Prerequisites"},{"location":"installation/docker/prerequisites/#prerequisites","text":"In order to run the docker version of EVAdb in a secure and performant manner, some prerequisites need to be fulfilled. Please make sure that you have a basic understanding of docker and how the web works before setting up this website. In order to follow setup and usage guides, it is important that you have an understanding on docker, SSL certificates (for https) and the performance of the system you are hosting your database at.","title":"Prerequisites"},{"location":"installation/docker/prerequisites/#physical-infrastructure","text":"Hardware Requirements To be able to host EVAdb, the hardware must have: 4TB NVMe/SSD Storage Additional performance improvements are gained by utilizing more RAM and CPU Power. EVAdb is meant to host multiple thousand exome cases. As is the case with such datasets, even storing only variants will have the database growing to be multiple terabytes in size. In order to have a nice user experience for the frontend, it is important that the backend database does not bog down even for large requests (f.e. all autosomal dominant variants for one sample). To be able to scale the amount of data, we recommend a physical server utilizing NVMe (or at least SSD) storage technologies. This will greatly increase the database performance for all queries. Make sure you have enough storage available for the expected amount of data. The initialized application will consume around 400GB without any cases added. Spinning Rust We advise heavily against running the databse on older HDD type storage media. Performance will be abysmal.","title":"Physical Infrastructure"},{"location":"installation/docker/prerequisites/#docker","text":"Docker Docker is a isolation technique prevalent in modern software development since it allows the automatic deployment of complex software stacks. Read more: Docker Get Started Docker Setup To be able to host EVAdb through Docker Images, make sure you have installed and correctly configured: Docker docker-compose If you desire to install the application via Docker, please familiarize yourself with the basic concepts of Docker. To deploy the application, we use docker-compose which allows us to deploy the stack of multiple containers through use of a single command. Please follow the installation instructions for docker on your favorite operating system over at docker.com . Some operating systems might need additional setup after installation of docker, typically adding the active user to the docker group. Make sure you follow these steps as well (postinstallation) . To be able to continue with the installation guide, please also install docker-compose .","title":"Docker"},{"location":"installation/docker/prerequisites/#ssl-certificates","text":"SSL Certificates Obtaining a certificate and private key pair is necessary to host EVAdb. Make sure you have obtained a pair and named them evadb.crt and evadb.key to run the application. SSL is used in https to encrypt connections to remote servers. In order to validate the servers identity to the client, the server needs to present a valid certificate. Valid certificates can be obtained from letsencrypt or your local universities IT department. To run EVAdb, you have to supply a certificate for use by the web service. Letsencrypt In order to use the following letsencrypt description, your server needs to be reachable from the Internet and have a known DNS entry. In order to request a valid certificate from letsencrypt, you can use the certbot application. It can be installed on any UNIX-like machine through the package manager of choice. Once installed, use certbot certonly --standalone to get a certificate for your server. For development purposes, it is enough to create a self-signed certificate. On UNIX-like machines the openssl tool can be used to create a self-signed certificate for use with EVAdb. openssl req -x509 -newkey rsa:4096 \\ -keyout <KEY_NAME> \\ -out <CERT_NAME> \\ -days 365 \\ --nodes This will print your certificate and its private key at KEY_NAME and CERT_NAME respectively. To supply the certificate and private key to evadb, they have to be named evadb.crt and evadb.key respectively.","title":"SSL Certificates"},{"location":"installation/docker/run/","text":"Starting the Application After building the application, starting the whole stack is as simple as running the following command. docker-compose File All docker-compose based command lines need to be executed from the root directory of the application, where the docker-compose.yml is located. Otherwise you can rely on standard docker commands. docker-compose up -d After some time, all containers will be started and isolated and your instance of EVAdb should be available at https://localhost:443 and https://localhost:8443 . If you are running on a remote server, you have to substitute localhost for the actual server name. If there are trouble getting a response from the server, you can use docker-compose logs [ -f ] [ CONTAINER_NAME ] to inspect the logs of all containers (if CONTAINER_NAME is omitted) or specific containers (supply the name). For further troubleshooting, it is possible to descend into the containers using the following commands. docker-compose exec [ CONTAINER_NAME ] [ TOOL ] # If the container is still running docker-compose run [ CONTAINER_NAME ] [ TOOL ] # If the container stopped To inspect the state of your container setup, please use docker-compose ps .","title":"First Start"},{"location":"installation/docker/run/#starting-the-application","text":"After building the application, starting the whole stack is as simple as running the following command. docker-compose File All docker-compose based command lines need to be executed from the root directory of the application, where the docker-compose.yml is located. Otherwise you can rely on standard docker commands. docker-compose up -d After some time, all containers will be started and isolated and your instance of EVAdb should be available at https://localhost:443 and https://localhost:8443 . If you are running on a remote server, you have to substitute localhost for the actual server name. If there are trouble getting a response from the server, you can use docker-compose logs [ -f ] [ CONTAINER_NAME ] to inspect the logs of all containers (if CONTAINER_NAME is omitted) or specific containers (supply the name). For further troubleshooting, it is possible to descend into the containers using the following commands. docker-compose exec [ CONTAINER_NAME ] [ TOOL ] # If the container is still running docker-compose run [ CONTAINER_NAME ] [ TOOL ] # If the container stopped To inspect the state of your container setup, please use docker-compose ps .","title":"Starting the Application"},{"location":"installation/native/","text":"Native Installation Under Construction This part of the documentation is under construction In order to install the EVAdb Applications natively on a server, please see the Documentation in the main EVAdb repository","title":"Installation"},{"location":"installation/native/#native-installation","text":"Under Construction This part of the documentation is under construction In order to install the EVAdb Applications natively on a server, please see the Documentation in the main EVAdb repository","title":"Native Installation"}]}